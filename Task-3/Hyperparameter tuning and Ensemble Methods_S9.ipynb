{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all the modules/packages required to complete the given task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier,VotingClassifier,AdaBoostClassifier,GradientBoostingClassifier,StackingClassifier,BaggingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import  GaussianProcessClassifier\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,f1_score,classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model-1 performs the Logistic-Regression on the given task and tuning is done using simple loops and the accuracy comes around 98.25 percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1(x_train,y_train,x_test,y_test):\n",
    "    print(\"Model-1 : Logistic Regression \")\n",
    "    param_grid={'solver':['liblinear','newton-cg','sag'],'max_iter':[10000]}\n",
    "    grid = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='accuracy')\n",
    "    grid.fit(x_train,y_train)\n",
    "    y_test_pred=grid.predict(x_test)\n",
    "    acc_test=round(accuracy_score(y_test_pred,y_test),4)*100\n",
    "    print(\"Accuracy of Model 1 on test set : \",acc_test)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Precision of Model 1 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Recall of Model 1 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"F1-score of Model-1 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])\n",
    "    print(\"Confusion Matrix of Model-1 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n",
    "    return grid.best_params_\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the model-2 which performs the KNearest algorithm.In this model-1,the performance of KNN on the given task is improved Firstly,the datasets is provided with all necessary cleaning and converting to numpy array.I have set a range of values for which ,it will tune the value of k on the validation set such that we can know the value of k whichs performs the best on the validation set.Then we used the best value of k for testing purposes and calculate the accuracy of the model,which comes around 96.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2(x_train,y_train,x_test,y_test):\n",
    "    print(\"Model-2 : K-Nearest Neighbors \")\n",
    "    k_range=[3,7,9,13,15,19,23,25]\n",
    "    param_grid=dict(n_neighbors=k_range)\n",
    "    grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "    grid.fit(x_train,y_train)\n",
    "    y_test_pred=grid.predict(x_test)\n",
    "    acc_t=round(accuracy_score(y_test_pred,y_test),4)*100\n",
    "    print(\"Accuracy of Model 2 on test set : \",acc_t)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Precision of Model 2 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Recall of Model 2 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"F1-score of Model-2 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])\n",
    "    print(\"Confusion Matrix of Model-2 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n",
    "    return grid.best_params_\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine Algorithm is performed onn the given model and accuracy obtained was 99.25 percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model3(x_train,y_train,x_test,y_test):\n",
    "    print(\"Model-3 : Support Vector Machine \")\n",
    "    param_grid={'C':[1,10,100,100],'gamma':['auto',0.1,0.01,0.001],'kernel':['rbf','poly']}\n",
    "    grid = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy')\n",
    "    grid.fit(x_train,y_train)\n",
    "    y_test_pred=grid.predict(x_test)\n",
    "    acc_test=round(accuracy_score(y_test_pred,y_test),4)*100\n",
    "    print(\"Accuracy of Model 3 on test set : \",acc_test)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Precision of Model 3 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Recall of Model 3 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"F1-score of Model-3 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])\n",
    "    print(\"Confusion Matrix of Model-3 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n",
    "    return grid.best_params_\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below model implements the DecisionTree Classification.Here we tune its different parameter and try to get the best parameter by performing holdout validation.Then we used the best parameters of the model on test-set and obtain an accuracy around 95 percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model4(x_train,y_train,x_test,y_test):\n",
    "    print(\"Model-4 : Decision Tree \")\n",
    "    param_grid={'criterion':['gini','entropy'],'max_depth':[5,7,9,13,15,23],'min_samples_leaf':[1,2,5]}\n",
    "    grid = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "    grid.fit(x_train,y_train)\n",
    "    y_test_pred=grid.predict(x_test)\n",
    "    acc_test=round(accuracy_score(y_test_pred,y_test),4)*100\n",
    "    print(\"Accuracy of Model 4 on test set : \",acc_test)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Precision of Model 4 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Recall of Model 4 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"F1-score of Model-4 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])\n",
    "    print(\"Confusion Matrix of Model-4 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n",
    "    return grid.best_params_\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given below function perform the Random Forest Classification on the given data.Hypereparameters are tuned according to the validation set and we test the best parameter on test data so that we can get an accuracy of nearly 98.3 percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model5(x_train,y_train,x_test,y_test):\n",
    "    print(\"Model-5 : Random Forest Classification  \")\n",
    "    param_grid={'n_estimators':[10,50,100,200],'criterion':['gini','entropy'],'max_depth':[5,6,8,13,15,23,25]}\n",
    "    grid = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "    grid.fit(x_train,y_train)\n",
    "    y_test_pred=grid.predict(x_test)\n",
    "    acc_test=round(accuracy_score(y_test_pred,y_test),4)*100\n",
    "    print(\"Accuracy of Model 5 on test set : \",acc_test)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Precision of Model 5 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Recall of Model 5 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"F1-score of Model-5 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])\n",
    "    print(\"Confusion Matrix of Model-5 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n",
    "    return grid.best_params_\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given below function perform the ExtraTrees Classification on the given data.Hypereparameters are tuned according to the validation set and we test the best parameter on test data so that we can get an accuracy more than 98.3 percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model6(x_train,y_train,x_test,y_test):\n",
    "    print(\"Model-6 : ExtraTrees Classification  \")\n",
    "    param_grid={'n_estimators':[10,50,100,200],'criterion':['gini','entropy'],'max_depth':[5,6,8,13,15,23,25]}\n",
    "    grid = GridSearchCV(ExtraTreesClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "    grid.fit(x_train,y_train)\n",
    "    y_test_pred=grid.predict(x_test)\n",
    "    acc_test=round(accuracy_score(y_test_pred,y_test),4)*100\n",
    "    print(\"Accuracy of Model 6 on test set : \",acc_test)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Precision of Model 6 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Recall of Model 6 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"F1-score of Model-6 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])\n",
    "    print(\"Confusion Matrix of Model-6 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n",
    "    return grid.best_params_\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given below is the VotingClassifier which trains on an ensemble of numerous models and predicts an output (class) based on their highest probability of chosen class as the output. It simply aggregates the findings of each classifier passed into Voting Classifier and predicts the output class based on the highest majority of voting. In this hard voting method was used to train the model,the predicted output class was class with highest majority of votes. The accuracy obtained was slightly less than the accuracy obtained from SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model7(x_train,x_test,y_train,y_test,estimator):\n",
    "    e=[('lr',LogisticRegression(solver=estimator[0]['solver'])),\n",
    "       ('knn',KNeighborsClassifier(n_neighbors=estimator[1]['n_neighbors'])),\n",
    "      ('svm',SVC(C=estimator[2]['C'],gamma=estimator[2]['gamma'],kernel='rbf')),\n",
    "      ('dt',DecisionTreeClassifier(criterion=estimator[3]['criterion'],max_depth=estimator[3]['max_depth'])),\n",
    "      ('rf',RandomForestClassifier(n_estimators=estimator[4]['n_estimators'],criterion=estimator[4]['criterion'],max_depth=estimator[4]['max_depth'])),\n",
    "      ('et',ExtraTreesClassifier(n_estimators=estimator[5]['n_estimators'],criterion=estimator[5]['criterion'],max_depth=estimator[5]['max_depth']))]\n",
    "    print(\"Model-7 : VotingClassifier\")\n",
    "    vot_hard=VotingClassifier(estimators = e, voting ='hard') \n",
    "    vot_hard.fit(x_train, y_train)\n",
    "    y_test_pred=vot_hard.predict(x_test)\n",
    "    acc_t=round(accuracy_score(y_test_pred,y_test),4)*100    #accuracy of the predicting model\n",
    "    print(\"Accuracy of Model 7 on test set : \",acc_t)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100   #precision of the predicting model\n",
    "    print(\"Precision of Model 7 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100      #recall_Score of the model\n",
    "    print(\"Recall of Model 7 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100      #f1_score of the model\n",
    "    print(\"F1-score of Model-7 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])   #confusion matrix of the model\n",
    "    print(\"Confusion Matrix of Model-7 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Bagging classifier is an ensemble meta-estimator that fits base classifiers each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. Such a meta-estimator can typically be used as a way to reduce the variance of a black-box estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it.\n",
    "\n",
    "The accuracy obtained was greater than 98.98 percent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model8(x_train,x_test,y_train,y_test,estimator):\n",
    "    print(\"Model-8 : BaggingClassifier\")\n",
    "    bag=BaggingClassifier(base_estimator=SVC(C=estimator[2]['C'],gamma=estimator[2]['gamma'],kernel='rbf'),n_estimators=200,random_state=5) \n",
    "    bag.fit(x_train, y_train)\n",
    "    y_test_pred=bag.predict(x_test)\n",
    "    acc_t=round(accuracy_score(y_test_pred,y_test),4)*100    #accuracy of the predicting model\n",
    "    print(\"Accuracy of Model 8 on test set : \",acc_t)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100   #precision of the predicting model\n",
    "    print(\"Precision of Model 8 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100      #recall_Score of the model\n",
    "    print(\"Recall of Model 8 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100      #f1_score of the model\n",
    "    print(\"F1-score of Model-8 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])   #confusion matrix of the model\n",
    "    print(\"Confusion Matrix of Model-8 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the boosting method in which I have used GradientBoosting and obtain an accuracy around 98.5 percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model9(x_train,x_test,y_train,y_test,estimator):\n",
    "    print(\"Model-9 Gradient-Boosting \")\n",
    "    gbc=GradientBoostingClassifier(n_estimators=200,learning_rate=0.1,subsample=1,random_state=0)\n",
    "    gbc.fit(x_train,y_train)\n",
    "    y_test_pred=gbc.predict(x_test)\n",
    "    acc_t=round(accuracy_score(y_test_pred,y_test),4)*100    #accuracy of the predicting model\n",
    "    print(\"Accuracy of Model 9 on test set : \",acc_t)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100   #precision of the predicting model\n",
    "    print(\"Precision of Model 9 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100      #recall_Score of the model\n",
    "    print(\"Recall of Model 9 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100      #f1_score of the model\n",
    "    print(\"F1-score of Model-9 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])   #confusion matrix of the model\n",
    "    print(\"Confusion Matrix of Model-9 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the implementation of StackingClassifier.Here,we stacked the results obtain from different classifier and stacked together and passed to a final classifier which is SVM and the result obtained was around 99.3 percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model10(x_train,x_test,y_train,y_test,estimator):\n",
    "    esti=[('lr',LogisticRegression(solver=estimator[0]['solver'])),\n",
    "          ('knn',KNeighborsClassifier(n_neighbors=estimator[1]['n_neighbors'])),\n",
    "          ('svm',SVC(C=estimator[2]['C'],gamma=estimator[2]['gamma'],kernel='rbf')),\n",
    "          ('dt',DecisionTreeClassifier(criterion=estimator[3]['criterion'],max_depth=estimator[3]['max_depth'])),\n",
    "          ('rf',RandomForestClassifier(n_estimators=estimator[4]['n_estimators'],criterion=estimator[4]['criterion'],max_depth=estimator[4]['max_depth'])),\n",
    "          ('et',ExtraTreesClassifier(n_estimators=estimator[5]['n_estimators'],criterion=estimator[5]['criterion'],max_depth=estimator[5]['max_depth']))]\n",
    "    print(\"Model-10 : Stacking Classifier \")\n",
    "    stc=StackingClassifier(estimators=esti,final_estimator=SVC(C=estimator[2]['C'],gamma=estimator[2]['gamma'],kernel='rbf'),cv=3)\n",
    "    stc.fit(x_train,y_train)\n",
    "    y_test_pred=stc.predict(x_test)\n",
    "    acc_t=round(accuracy_score(y_test_pred,y_test),4)*100    #accuracy of the predicting model\n",
    "    print(\"Accuracy of Model 10 on test set : \",acc_t)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100   #precision of the predicting model\n",
    "    print(\"Precision of Model 10 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100      #recall_Score of the model\n",
    "    print(\"Recall of Model 10 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100      #f1_score of the model\n",
    "    print(\"F1-score of Model-10 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])   #confusion matrix of the model\n",
    "    print(\"Confusion Matrix of Model-10 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model-1 : Logistic Regression \n",
      "Accuracy of Model 1 on test set :  97.76\n",
      "Precision of Model 1 on test set :  97.76\n",
      "Recall of Model 1 on test set :  97.76\n",
      "F1-score of Model-1 on test set :  97.75\n",
      "Confusion Matrix of Model-1 on test set : \n",
      "[[887   0   0   0   0   0   0   0]\n",
      " [  0 880   1   0   0   2   0   0]\n",
      " [  0   1 875   1   0   1   0   0]\n",
      " [  0   0   0 849   0   3  37   0]\n",
      " [  0   0   0   1 888   2   0   0]\n",
      " [  0   1   0   5   0 849  18   0]\n",
      " [  0   0   7  50   0  24 797   2]\n",
      " [  0   0   0   1   0   1   0 857]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  1.00000000 1.00000000 1.00000000       887\n",
      "           2  0.99773243 0.99660249 0.99716714       883\n",
      "           3  0.99093998 0.99658314 0.99375355       878\n",
      "           4  0.93605292 0.95500562 0.94543430       889\n",
      "           5  1.00000000 0.99663300 0.99831366       891\n",
      "           6  0.96258503 0.97250859 0.96752137       873\n",
      "           7  0.93544601 0.90568182 0.92032333       880\n",
      "           8  0.99767171 0.99767171 0.99767171       859\n",
      "\n",
      "    accuracy                      0.97755682      7040\n",
      "   macro avg  0.97755351 0.97758580 0.97752313      7040\n",
      "weighted avg  0.97751751 0.97755682 0.97749055      7040\n",
      "\n",
      "==========================================================================================================\n",
      "Model-2 : K-Nearest Neighbors \n",
      "Accuracy of Model 2 on test set :  97.63\n",
      "Precision of Model 2 on test set :  97.63\n",
      "Recall of Model 2 on test set :  97.64\n",
      "F1-score of Model-2 on test set :  97.63\n",
      "Confusion Matrix of Model-2 on test set : \n",
      "[[887   0   0   0   0   0   0   0]\n",
      " [  0 877   2   0   0   4   0   0]\n",
      " [  0   5 871   2   0   0   0   0]\n",
      " [  0   0   0 840   0   2  47   0]\n",
      " [  0   0   0   0 891   0   0   0]\n",
      " [  0   5   1  18   1 834  14   0]\n",
      " [  1   0  10  40   0  15 814   0]\n",
      " [  0   0   0   0   0   0   0 859]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  0.99887387 1.00000000 0.99943662       887\n",
      "           2  0.98872604 0.99320498 0.99096045       883\n",
      "           3  0.98529412 0.99202733 0.98864926       878\n",
      "           4  0.93333333 0.94488189 0.93907211       889\n",
      "           5  0.99887892 1.00000000 0.99943915       891\n",
      "           6  0.97543860 0.95532646 0.96527778       873\n",
      "           7  0.93028571 0.92500000 0.92763533       880\n",
      "           8  1.00000000 1.00000000 1.00000000       859\n",
      "\n",
      "    accuracy                      0.97627841      7040\n",
      "   macro avg  0.97635383 0.97630508 0.97630884      7040\n",
      "weighted avg  0.97628952 0.97627841 0.97626341      7040\n",
      "\n",
      "==========================================================================================================\n",
      "Model-3 : Support Vector Machine \n",
      "Accuracy of Model 3 on test set :  99.55000000000001\n",
      "Precision of Model 3 on test set :  99.55000000000001\n",
      "Recall of Model 3 on test set :  99.55000000000001\n",
      "F1-score of Model-3 on test set :  99.55000000000001\n",
      "Confusion Matrix of Model-3 on test set : \n",
      "[[887   0   0   0   0   0   0   0]\n",
      " [  0 883   0   0   0   0   0   0]\n",
      " [  0   0 877   1   0   0   0   0]\n",
      " [  0   0   0 880   0   0   9   0]\n",
      " [  0   0   0   0 891   0   0   0]\n",
      " [  0   1   0   2   0 867   3   0]\n",
      " [  0   0   0   9   1   6 864   0]\n",
      " [  0   0   0   0   0   0   0 859]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  1.00000000 1.00000000 1.00000000       887\n",
      "           2  0.99886878 1.00000000 0.99943407       883\n",
      "           3  1.00000000 0.99886105 0.99943020       878\n",
      "           4  0.98654709 0.98987627 0.98820887       889\n",
      "           5  0.99887892 1.00000000 0.99943915       891\n",
      "           6  0.99312715 0.99312715 0.99312715       873\n",
      "           7  0.98630137 0.98181818 0.98405467       880\n",
      "           8  1.00000000 1.00000000 1.00000000       859\n",
      "\n",
      "    accuracy                      0.99545455      7040\n",
      "   macro avg  0.99546541 0.99546033 0.99546176      7040\n",
      "weighted avg  0.99545281 0.99545455 0.99545257      7040\n",
      "\n",
      "==========================================================================================================\n",
      "Model-4 : Decision Tree \n",
      "Accuracy of Model 4 on test set :  96.50999999999999\n",
      "Precision of Model 4 on test set :  96.50999999999999\n",
      "Recall of Model 4 on test set :  96.53\n",
      "F1-score of Model-4 on test set :  96.52\n",
      "Confusion Matrix of Model-4 on test set : \n",
      "[[885   0   1   0   1   0   0   0]\n",
      " [  0 854  14   1   2  12   0   0]\n",
      " [  0   6 859   6   0   6   1   0]\n",
      " [  1   0   0 816   2   1  69   0]\n",
      " [  0   1   2   0 885   2   1   0]\n",
      " [  0   8   1   8   0 835  21   0]\n",
      " [  1   0   1  36   0  40 802   0]\n",
      " [  0   0   0   1   0   0   0 858]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  0.99774521 0.99774521 0.99774521       887\n",
      "           2  0.98273878 0.96715742 0.97488584       883\n",
      "           3  0.97835991 0.97835991 0.97835991       878\n",
      "           4  0.94009217 0.91788526 0.92885600       889\n",
      "           5  0.99438202 0.99326599 0.99382369       891\n",
      "           6  0.93191964 0.95647194 0.94403618       873\n",
      "           7  0.89709172 0.91136364 0.90417136       880\n",
      "           8  1.00000000 0.99883586 0.99941759       859\n",
      "\n",
      "    accuracy                      0.96505682      7040\n",
      "   macro avg  0.96529118 0.96513565 0.96516197      7040\n",
      "weighted avg  0.96527006 0.96505682 0.96511196      7040\n",
      "\n",
      "==========================================================================================================\n",
      "Model-5 : Random Forest Classification  \n",
      "Accuracy of Model 5 on test set :  98.45\n",
      "Precision of Model 5 on test set :  98.46000000000001\n",
      "Recall of Model 5 on test set :  98.46000000000001\n",
      "F1-score of Model-5 on test set :  98.46000000000001\n",
      "Confusion Matrix of Model-5 on test set : \n",
      "[[887   0   0   0   0   0   0   0]\n",
      " [  0 879   2   0   0   2   0   0]\n",
      " [  0   1 871   3   0   3   0   0]\n",
      " [  0   0   0 845   0   0  44   0]\n",
      " [  0   0   0   0 889   2   0   0]\n",
      " [  0   2   0   1   0 862   8   0]\n",
      " [  0   0   7  21   0  13 839   0]\n",
      " [  0   0   0   0   0   0   0 859]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  1.00000000 1.00000000 1.00000000       887\n",
      "           2  0.99659864 0.99546999 0.99603399       883\n",
      "           3  0.98977273 0.99202733 0.99089875       878\n",
      "           4  0.97126437 0.95050619 0.96077317       889\n",
      "           5  1.00000000 0.99775533 0.99887640       891\n",
      "           6  0.97732426 0.98739977 0.98233618       873\n",
      "           7  0.94163861 0.95340909 0.94748730       880\n",
      "           8  1.00000000 1.00000000 1.00000000       859\n",
      "\n",
      "    accuracy                      0.98451705      7040\n",
      "   macro avg  0.98457483 0.98457096 0.98455072      7040\n",
      "weighted avg  0.98456209 0.98451705 0.98451728      7040\n",
      "\n",
      "==========================================================================================================\n",
      "Model-6 : ExtraTrees Classification  \n",
      "Accuracy of Model 6 on test set :  98.76\n",
      "Precision of Model 6 on test set :  98.77\n",
      "Recall of Model 6 on test set :  98.77\n",
      "F1-score of Model-6 on test set :  98.77\n",
      "Confusion Matrix of Model-6 on test set : \n",
      "[[887   0   0   0   0   0   0   0]\n",
      " [  0 880   2   0   0   1   0   0]\n",
      " [  0   1 873   1   0   3   0   0]\n",
      " [  0   0   0 853   0   0  36   0]\n",
      " [  0   0   0   0 890   1   0   0]\n",
      " [  0   0   0   6   0 864   3   0]\n",
      " [  0   0   5  19   0   9 847   0]\n",
      " [  0   0   0   0   0   0   0 859]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  1.00000000 1.00000000 1.00000000       887\n",
      "           2  0.99886493 0.99660249 0.99773243       883\n",
      "           3  0.99204545 0.99430524 0.99317406       878\n",
      "           4  0.97042093 0.95950506 0.96493213       889\n",
      "           5  1.00000000 0.99887767 0.99943852       891\n",
      "           6  0.98405467 0.98969072 0.98686465       873\n",
      "           7  0.95598194 0.96250000 0.95922990       880\n",
      "           8  1.00000000 1.00000000 1.00000000       859\n",
      "\n",
      "    accuracy                      0.98764205      7040\n",
      "   macro avg  0.98767099 0.98768515 0.98767146      7040\n",
      "weighted avg  0.98765081 0.98764205 0.98763979      7040\n",
      "\n",
      "==========================================================================================================\n",
      "[{'max_iter': 10000, 'solver': 'newton-cg'}, {'n_neighbors': 3}, {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}, {'criterion': 'entropy', 'max_depth': 13, 'min_samples_leaf': 1}, {'criterion': 'entropy', 'max_depth': 25, 'n_estimators': 200}, {'criterion': 'entropy', 'max_depth': 25, 'n_estimators': 200}]\n",
      "Model-7 : VotingClassifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model 7 on test set :  99.03\n",
      "Precision of Model 7 on test set :  99.03999999999999\n",
      "Recall of Model 7 on test set :  99.03\n",
      "F1-score of Model-7 on test set :  99.03\n",
      "Confusion Matrix of Model-7 on test set : \n",
      "[[887   0   0   0   0   0   0   0]\n",
      " [  0 881   1   0   0   1   0   0]\n",
      " [  0   1 876   1   0   0   0   0]\n",
      " [  0   0   0 867   0   0  22   0]\n",
      " [  0   0   0   0 891   0   0   0]\n",
      " [  0   0   0   2   0 869   2   0]\n",
      " [  0   0   5  24   0   9 842   0]\n",
      " [  0   0   0   0   0   0   0 859]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  1.00000000 1.00000000 1.00000000       887\n",
      "           2  0.99886621 0.99773499 0.99830028       883\n",
      "           3  0.99319728 0.99772210 0.99545455       878\n",
      "           4  0.96979866 0.97525309 0.97251823       889\n",
      "           5  1.00000000 1.00000000 1.00000000       891\n",
      "           6  0.98862344 0.99541810 0.99200913       873\n",
      "           7  0.97228637 0.95681818 0.96449026       880\n",
      "           8  1.00000000 1.00000000 1.00000000       859\n",
      "\n",
      "    accuracy                      0.99034091      7040\n",
      "   macro avg  0.99034649 0.99036831 0.99034656      7040\n",
      "weighted avg  0.99032065 0.99034091 0.99031994      7040\n",
      "\n",
      "===========================================================================================================\n",
      "Model-8 : BaggingClassifier\n",
      "Accuracy of Model 8 on test set :  99.56\n",
      "Precision of Model 8 on test set :  99.56\n",
      "Recall of Model 8 on test set :  99.56\n",
      "F1-score of Model-8 on test set :  99.56\n",
      "Confusion Matrix of Model-8 on test set : \n",
      "[[887   0   0   0   0   0   0   0]\n",
      " [  0 883   0   0   0   0   0   0]\n",
      " [  0   0 877   1   0   0   0   0]\n",
      " [  0   0   0 882   0   0   7   0]\n",
      " [  0   0   0   0 891   0   0   0]\n",
      " [  0   1   0   2   1 866   3   0]\n",
      " [  0   0   0   8   1   7 864   0]\n",
      " [  0   0   0   0   0   0   0 859]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  1.00000000 1.00000000 1.00000000       887\n",
      "           2  0.99886878 1.00000000 0.99943407       883\n",
      "           3  1.00000000 0.99886105 0.99943020       878\n",
      "           4  0.98768197 0.99212598 0.98989899       889\n",
      "           5  0.99776036 1.00000000 0.99887892       891\n",
      "           6  0.99198167 0.99198167 0.99198167       873\n",
      "           7  0.98855835 0.98181818 0.98517674       880\n",
      "           8  1.00000000 1.00000000 1.00000000       859\n",
      "\n",
      "    accuracy                      0.99559659      7040\n",
      "   macro avg  0.99560639 0.99559836 0.99560007      7040\n",
      "weighted avg  0.99559464 0.99559659 0.99559330      7040\n",
      "\n",
      "===========================================================================================================\n",
      "Model-9 Gradient-Boosting \n",
      "Accuracy of Model 9 on test set :  98.58\n",
      "Precision of Model 9 on test set :  98.58\n",
      "Recall of Model 9 on test set :  98.59\n",
      "F1-score of Model-9 on test set :  98.58\n",
      "Confusion Matrix of Model-9 on test set : \n",
      "[[887   0   0   0   0   0   0   0]\n",
      " [  0 879   2   0   0   2   0   0]\n",
      " [  0   2 866   2   0   7   1   0]\n",
      " [  0   0   0 848   0   1  40   0]\n",
      " [  0   0   0   1 889   1   0   0]\n",
      " [  0   2   0   1   0 863   7   0]\n",
      " [  0   0   2  15   0  13 850   0]\n",
      " [  0   0   0   1   0   0   0 858]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  1.00000000 1.00000000 1.00000000       887\n",
      "           2  0.99546999 0.99546999 0.99546999       883\n",
      "           3  0.99540230 0.98633257 0.99084668       878\n",
      "           4  0.97695853 0.95388076 0.96528173       889\n",
      "           5  1.00000000 0.99775533 0.99887640       891\n",
      "           6  0.97294250 0.98854525 0.98068182       873\n",
      "           7  0.94654788 0.96590909 0.95613048       880\n",
      "           8  1.00000000 0.99883586 0.99941759       859\n",
      "\n",
      "    accuracy                      0.98579545      7040\n",
      "   macro avg  0.98591515 0.98584111 0.98583809      7040\n",
      "weighted avg  0.98591197 0.98579545 0.98581356      7040\n",
      "\n",
      "===========================================================================================================\n",
      "Model-10 : Stacking Classifier \n",
      "Accuracy of Model 10 on test set :  98.55000000000001\n",
      "Precision of Model 10 on test set :  98.56\n",
      "Recall of Model 10 on test set :  98.6\n",
      "F1-score of Model-10 on test set :  98.56\n",
      "Confusion Matrix of Model-10 on test set : \n",
      "[[887   0   0   0   0   0   0   0]\n",
      " [  0 882   0   0   0   1   0   0]\n",
      " [  0   0 878   0   0   0   0   0]\n",
      " [  0   0   0 815   0   0  74   0]\n",
      " [  0   0   0   0 891   0   0   0]\n",
      " [  0   1   0   1   0 869   2   0]\n",
      " [  1   0   7  10   0   5 857   0]\n",
      " [  0   0   0   0   0   0   0 859]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  0.99887387 1.00000000 0.99943662       887\n",
      "           2  0.99886750 0.99886750 0.99886750       883\n",
      "           3  0.99209040 1.00000000 0.99602950       878\n",
      "           4  0.98668281 0.91676040 0.95043732       889\n",
      "           5  1.00000000 1.00000000 1.00000000       891\n",
      "           6  0.99314286 0.99541810 0.99427918       873\n",
      "           7  0.91854234 0.97386364 0.94539437       880\n",
      "           8  1.00000000 1.00000000 1.00000000       859\n",
      "\n",
      "    accuracy                      0.98551136      7040\n",
      "   macro avg  0.98602497 0.98561370 0.98555556      7040\n",
      "weighted avg  0.98601541 0.98551136 0.98549797      7040\n",
      "\n",
      "===========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train=pd.read_excel('cTTD_features_with_Labels/S9/trainset_60.xls')  #reading the xls file into dataframe\n",
    "    validate=pd.read_excel('cTTD_features_with_Labels/S9/validate_20.xls')\n",
    "    test=pd.read_excel('cTTD_features_with_Labels/S9/testset_20.xls')\n",
    "    \n",
    "    x_tr=train.drop(43,axis=1)    #separating the target values\n",
    "    y_tr=train[43]\n",
    "    x_v=validate.drop(43,axis=1)\n",
    "    y_v=validate[43]\n",
    "    x_te=test.drop(43,axis=1)\n",
    "    y_te=test[43]\n",
    "    \n",
    "    x_train=x_tr.to_numpy()        # converting dataframe to numpy array\n",
    "    y_train=y_tr.to_numpy()\n",
    "    x_val=x_v.to_numpy()\n",
    "    y_val=y_v.to_numpy()\n",
    "    x_test=x_te.to_numpy()\n",
    "    y_test=y_te.to_numpy()\n",
    "    \n",
    "    sc=StandardScaler()\n",
    "    x_train=sc.fit_transform(x_train)       #standardizing the features for better traing process\n",
    "    x_val=sc.fit_transform(x_val)\n",
    "    x_test=sc.fit_transform(x_test)\n",
    "    estimator=[]\n",
    "    \n",
    "    x_train=np.concatenate((x_train,x_val))  #Now combining both training and validation data\n",
    "    y_train=np.concatenate((y_train,y_val))  #Now combing the target values of training and validation data\n",
    "    \n",
    "    \n",
    "    estimator.append(model1(x_train,y_train,x_test,y_test))\n",
    "    print(\"==========================================================================================================\")\n",
    "    \n",
    "    estimator.append(model2(x_train,y_train,x_test,y_test))\n",
    "    print(\"==========================================================================================================\")\n",
    "    \n",
    "    \n",
    "    estimator.append(model3(x_train,y_train,x_test,y_test))\n",
    "    print(\"==========================================================================================================\")\n",
    "    \n",
    "    estimator.append(model4(x_train,y_train,x_test,y_test))\n",
    "    print(\"==========================================================================================================\")\n",
    "    \n",
    "    \n",
    "    estimator.append(model5(x_train,y_train,x_test,y_test))\n",
    "    print(\"==========================================================================================================\")\n",
    "    \n",
    "    estimator.append(model6(x_train,y_train,x_test,y_test))\n",
    "    print(\"==========================================================================================================\")\n",
    "    \n",
    "    print(estimator)\n",
    "    \n",
    "   \n",
    "    model7(x_train,x_test,y_train,y_test,estimator)\n",
    "    print(\"===========================================================================================================\")\n",
    "    \n",
    "    model8(x_train,x_test,y_train,y_test,estimator)\n",
    "    print(\"===========================================================================================================\")\n",
    "    \n",
    "    model9(x_train,x_test,y_train,y_test,estimator)\n",
    "    print(\"===========================================================================================================\")\n",
    "    \n",
    "    model10(x_train,x_test,y_train,y_test,estimator)\n",
    "    print(\"===========================================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
