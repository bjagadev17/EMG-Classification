{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, the aim of the task is to share the results (accuracy score/performance) of two machine learning model i.e Support Vector Machine and Stochastic Gradient Descent Method.But,I have used many other classification algorithms to see which performs the best among all the algorithms.\n",
    "The datasets was provided to perform the task.It was boardly divided such that 60% of data was for training the model,20% of data was to validate the model such that we can tune its hyperparameters and its performance is improved and the rest 20% was for testing purpose.\n",
    "\n",
    "So Let's code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all the modules/packages required to complete the given task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import  GaussianProcessClassifier\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,f1_score,classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the model-1 which performs the KNearest algorithm.In this model-1,the performance of KNN on the given task is improved\n",
    "Firstly,the datasets is provided with all necessary cleaning and converting to numpy array.I have set a range of values for which ,it will tune the value of k on the validation set such that we can know the value of k whichs performs the best on the validation set.Then we used the best value  of k for testing purposes and calculate the accuracy of the model,which comes to be in between 93 and 94 percent.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1(x_train,y_train,x_val,y_val,x_test,y_test):\n",
    "    k_range=[5,7,10,12,18,25]                              #different value of k in knn and to obtain the best suitable value\n",
    "    a=[]\n",
    "    for i in k_range:\n",
    "        knn=KNeighborsClassifier(n_neighbors=i)\n",
    "        knn.fit(x_train,y_train)\n",
    "        y_val_pred=knn.predict(x_val)\n",
    "        acc=round(accuracy_score(y_val_pred,y_val),4)*100\n",
    "        a.append(acc)                                     #appending accuracy obtained from  training the model with different parameter\n",
    "    m=max(a)      #getting the maximum accuracy from validation set                          \n",
    "    p=a.index(m)  #getting the index of the max_accuracy\n",
    "    knn=KNeighborsClassifier(n_neighbors=k_range[p]) #again training the model with best hyperparameter\n",
    "    x_train=np.concatenate((x_train,x_val))  #Now combining both training and validation data\n",
    "    y_train=np.concatenate((y_train,y_val))  #Now combing the target values of training and validation data\n",
    "    knn.fit(x_train,y_train) #fitting the training data into model\n",
    "    y_test_pred=knn.predict(x_test)\n",
    "    print(\"Model-1 : K-Nearest Neighbors\")\n",
    "    acc_t=round(accuracy_score(y_test_pred,y_test),4)*100 #accuracy from accuracy_score\n",
    "    print(\"Accuracy of Model 1 on test set : \",acc_t)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100 #precision of the model\n",
    "    print(\"Precision of Model 1 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100  #recall of the model\n",
    "    print(\"Recall of Model 1 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100  #f1_score of the model\n",
    "    print(\"F1-score of Model-1 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8]) #confusion-matrix of the model\n",
    "    print(\"Confusion Matrix of Model-1 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model-2 performs the Logistic-Regression on the given task and tuning is done using simple loops and the accuracy comes out to be in beween 92 and 93."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2(x_train,y_train,x_val,y_val,x_test,y_test):\n",
    "    solver=['liblinear','newton-cg','sag','saga','lbfgs'] #taking different hyperparameters to regularize the logistic regresson model\n",
    "    multi_class=['auto']\n",
    "    a=[]\n",
    "    for i in solver:\n",
    "        lr=LogisticRegression(solver=i,max_iter=100000)   #tuning the model each time with a new hyperparameter\n",
    "        lr.fit(x_train,y_train)\n",
    "        y_val_pred=lr.predict(x_val)\n",
    "        acc=round(accuracy_score(y_val_pred,y_val),4)*100\n",
    "        a.append(acc)\n",
    "    m=max(a)       #getting the maximum accuracy from validation set\n",
    "    p=a.index(m)   #getting the index of the max_accuracy\n",
    "    lr=LogisticRegression(solver=solver[p])  #again training the model with best hyperparameter\n",
    "    x_train=np.concatenate((x_train,x_val))  #Now combining both training and validation data\n",
    "    y_train=np.concatenate((y_train,y_val))  #Now combing the target values of training and validation data\n",
    "    lr.fit(x_train,y_train)\n",
    "    y_test_pred=lr.predict(x_test)   #fitting the training data into model\n",
    "    print(\"Model-2 : Logistic Regression\")  \n",
    "    acc_t=round(accuracy_score(y_test_pred,y_test),4)*100 #accuracy of the model\n",
    "    print(\"Accuracy of Model 2 on test set : \",acc_t)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100   #precision score\n",
    "    print(\"Precision of Model 2 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Recall of Model 2 on test set : \",rec)      #recall_score\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"F1-score of Model-2 on test set : \",f_score)    #f1_Score\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8]) #confusion matrix\n",
    "    print(\"Confusion Matrix of Model-2 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below model implements the DecisionTree Classification.Here we tune its different parameter and try to get the best parameter by performing holdout validation.Then we used the best parameters of the model on test-set and obtain an accuracy in between 92 and 93 percent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model3(x_train,y_train,x_val,y_val,x_test,y_test):\n",
    "    criterion=['gini','entropy']          #first hyperparamter list\n",
    "    max_depth=[1,10,20,50,100]            #second hyperparameter list\n",
    "    feature=[]                            #list that will contain different combination of hyperparameter\n",
    "    a=[]                                  #list will contain different accuracy by combining different parameters\n",
    "    for i in criterion:\n",
    "        for j in max_depth:\n",
    "            dt=DecisionTreeClassifier(criterion=i,max_depth=j)  \n",
    "            dt.fit(x_train,y_train)\n",
    "            y_val_pred=dt.predict(x_val)\n",
    "            acc=round(accuracy_score(y_val_pred,y_val),4)*100\n",
    "            feature.append((i,j))\n",
    "            a.append(acc)\n",
    "    m=max(a) #getting the maximum accuracy\n",
    "    p=a.index(m) #getting the index of max accuracy to obtain the best hyperparameters\n",
    "    dt=DecisionTreeClassifier(criterion=feature[p][0],max_depth=feature[p][1])\n",
    "    x_train=np.concatenate((x_train,x_val))  #Now combining both training and validation data\n",
    "    y_train=np.concatenate((y_train,y_val))  #Now combing the target values of training and validation data\n",
    "    dt.fit(x_train,y_train)  #fitting the training data into the model\n",
    "    y_test_pred=dt.predict(x_test)   #predicting the test data\n",
    "    print(\"Model-3: Decision Tree \")\n",
    "    acc_t=round(accuracy_score(y_test_pred,y_test),4)*100    #accuracy of the predicting model\n",
    "    print(\"Accuracy of Model 3 on test set : \",acc_t)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100     #precision of the predicting model\n",
    "    print(\"Precision of Model 3 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100        #recall_Score of the model\n",
    "    print(\"Recall of Model 3 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100           #f1_score of the model\n",
    "    print(\"F1-score of Model-3 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])      #confusion matrix of the model\n",
    "    print(\"Confusion Matrix of Model-3 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n",
    "    \n",
    "\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The given below code performs Naive Bayes analysis on the given datasets .As NaiveBayes much do not have any parameters to tune .So I directly trained the model and got an accuracy of around 86 percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model4(x_train,y_train,x_val,y_val,x_test,y_test):\n",
    "    gnb=GaussianNB()\n",
    "    x_train=np.concatenate((x_train,x_val))  #Now combining both training and validation data\n",
    "    y_train=np.concatenate((y_train,y_val))  #Now combing the target values of training and validation data\n",
    "    gnb.fit(x_train,y_train)\n",
    "    y_test_pred=gnb.predict(x_test)\n",
    "    print(\"Model-4: Naive Bayes \")\n",
    "    acc_t=round(accuracy_score(y_test_pred,y_test),4)*100\n",
    "    print(\"Accuracy of Model 4 on test set : \",acc_t)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Precision of Model 4 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Recall of Model 4 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"F1-score of Model-4 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])\n",
    "    print(\"Confusion Matrix of Model-4 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given below function perform the Random Forest Classification on the given data.Hypereparameters are tuned according to the validation set and we test the best parameter on test data so that we can get an accuracy of nearly 98 percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model5(x_train,y_train,x_val,y_val,x_test,y_test):\n",
    "    n_estimators=[1,10,20,100,200]    #first hyperparamter list\n",
    "    criterion=['gini','entropy']      #second hyperparameter list\n",
    "    feature=[]                        #list that will contain different combination of hyperparameter\n",
    "    a=[]                              #list will contain different accuracy by combining different parameters\n",
    "    for i in n_estimators:\n",
    "        for j in criterion:\n",
    "            rf=RandomForestClassifier(criterion=j,n_estimators=i)\n",
    "            rf.fit(x_train,y_train)\n",
    "            y_val_pred=rf.predict(x_val)\n",
    "            acc=round(accuracy_score(y_val_pred,y_val),4)*100\n",
    "            feature.append((i,j))\n",
    "            a.append(acc)\n",
    "    m=max(a)       #getting the maximum accuracy\n",
    "    p=a.index(m)   #getting the index of max accuracy to obtain the best hyperparameters\n",
    "    rf=RandomForestClassifier(criterion=feature[p][1],n_estimators=feature[p][0])\n",
    "    x_train=np.concatenate((x_train,x_val))  #Now combining both training and validation data\n",
    "    y_train=np.concatenate((y_train,y_val))  #Now combing the target values of training and validation data\n",
    "    rf.fit(x_train,y_train)  #fitting the training data into the model\n",
    "    y_test_pred=rf.predict(x_test)  #predicting the test data\n",
    "    print(\"Model-5: Random-Forest \")\n",
    "    acc_t=round(accuracy_score(y_test_pred,y_test),4)*100    #accuracy of the predicting model\n",
    "    print(\"Accuracy of Model 5 on test set : \",acc_t)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100   #precision of the predicting model\n",
    "    print(\"Precision of Model 5 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100      #recall_Score of the model\n",
    "    print(\"Recall of Model 5 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100      #f1_score of the model\n",
    "    print(\"F1-score of Model-5 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])   #confusion matrix of the model\n",
    "    print(\"Confusion Matrix of Model-5 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine Algorithm is performed onn the given model and accuracy obtained was 97 percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model6(x_train,y_train,x_val,y_val,x_test,y_test):\n",
    "    C=[1,10,100,1000]             #first hyper-parameter list\n",
    "    gamma=[0.0001,0.001,0.01,0.1,1,10]              #second hyper-parameter list\n",
    "    kernel=['rbf','poly','linear']    #third hyper-parameter list\n",
    "    feature=[]                        #list that will contain different combination of hyperparameter\n",
    "    a=[]                              #list will contain different accuracy by combining different parameters\n",
    "    for i in C:\n",
    "        for j in gamma:\n",
    "            for k in kernel:\n",
    "                svc=SVC(C=i,gamma=j,kernel=k)\n",
    "                svc.fit(x_train,y_train)\n",
    "                y_val_pred=svc.predict(x_val)\n",
    "                acc=round(accuracy_score(y_val_pred,y_val),4)*100\n",
    "                feature.append((i,j,k))\n",
    "                a.append(acc)\n",
    "    m=max(a)                        #getting the maximum accuracy\n",
    "    p=a.index(m)                    #getting the index of max accuracy to obtain the best hyperparameters\n",
    "    print(a)\n",
    "    print(feature[p])\n",
    "    svc=SVC(C=feature[p][0],gamma=feature[p][1],kernel=feature[p][2])\n",
    "    x_train=np.concatenate((x_train,x_val))  #Now combining both training and validation data\n",
    "    y_train=np.concatenate((y_train,y_val))  #Now combing the target values of training and validation data\n",
    "    svc.fit(x_train,y_train)        #fitting the training data into the model\n",
    "    y_test_pred=svc.predict(x_test) #predicting the test data\n",
    "    print(\"Model-6: Support Vector Machine \")\n",
    "    acc_t=round(accuracy_score(y_test_pred,y_test),4)*100                    #accuracy of the predicting model\n",
    "    print(\"Accuracy of Model 6 on test set : \",acc_t)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100     #precision of the predicting model\n",
    "    print(\"Precision of Model 6 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100        #recall_Score of the model\n",
    "    print(\"Recall of Model 6 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100        #f1_score of the model\n",
    "    print(\"F1-score of Model-6 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])    #confusion matrix of the model\n",
    "    print(\"Confusion Matrix of Model-6 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD Classification Algorithm is performed onn the given model and accuracy obtained was 93 percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model7(x_train,y_train,x_val,y_val,x_test,y_test):\n",
    "    loss=['squared_hinge','modified_huber','perceptron','log','hinge']  #first hyper-parameter list\n",
    "    alpha=[0.00001,0.001,0.1,0.01]                                      #second hyper-parameter list\n",
    "    learning_rate=['adaptive','optimal','invscaling']                   #third hyper-parameter list\n",
    "    feature=[]                                                          #list that will contain different combination of hyperparameter\n",
    "    a=[]                                                                #list will contain different accuracy by combining different parameters\n",
    "    for i in loss:\n",
    "        for j in alpha:\n",
    "            for k in learning_rate:\n",
    "                    sgd=SGDClassifier(loss=i,alpha=j,learning_rate=k,eta0=1,max_iter=1000000)\n",
    "                    sgd.fit(x_train,y_train)\n",
    "                    y_val_pred=sgd.predict(x_val)\n",
    "                    acc=round(accuracy_score(y_val_pred,y_val),4)*100\n",
    "                    feature.append((i,j,k))\n",
    "                    a.append(acc)\n",
    "    m=max(a)                        #getting the maximum accuracy\n",
    "    p=a.index(m)                    #getting the index of max accuracy to obtain the best hyperparameters\n",
    "    print(feature[p])\n",
    "    sgd=SGDClassifier(loss=feature[p][0],alpha=feature[p][1],learning_rate=feature[p][2],max_iter=100000,eta0=1)\n",
    "    x_train=np.concatenate((x_train,x_val))  #Now combining both training and validation data\n",
    "    y_train=np.concatenate((y_train,y_val))  #Now combing the target values of training and validation data\n",
    "    sgd.fit(x_train,y_train)        #fitting the training data into the model\n",
    "    y_test_pred=sgd.predict(x_test) #predicting the test data\n",
    "    print(\"Model-7: SGD Method \")\n",
    "    acc_t=round(accuracy_score(y_test_pred,y_test),4)*100         #accuracy of the predicting model\n",
    "    print(\"Accuracy of Model 7 on test set : \",acc_t)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100    #precision of the predicting model\n",
    "    print(\"Precision of Model 7 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100        #recall_Score of the model\n",
    "    print(\"Recall of Model 7 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100        #f1_score of the model\n",
    "    print(\"F1-score of Model-7 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])    #confusion matrix of the model\n",
    "    print(\"Confusion Matrix of Model-7 on test set : \")\n",
    "    print(con_mat)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's the main fuction where dataset which was in xls format is converted into Dataframe using pandas then this data is explored and cleaned for further operation to be performed and then stored in a numpy array so that we can easily perform our task.Here different models are called in which data in the form of array is passed as arguments and obtain the metric parameters such as accuracy score,precision,recall,F1-score and confusion-matrix.From this metrics we evaluated how different models performed on the given dataset.Here every model's hyperparameters are tuned with the help of loops.The best accuracy was ovtained for Random Forest follwed by Support Vector Machine Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model-1 : K-Nearest Neighbors\n",
      "Accuracy of Model 1 on test set :  96.39\n",
      "Precision of Model 1 on test set :  96.44\n",
      "Recall of Model 1 on test set :  96.46000000000001\n",
      "F1-score of Model-1 on test set :  96.43\n",
      "Confusion Matrix of Model-1 on test set : \n",
      "[[877   0   1   0   0   1   0   0]\n",
      " [  0 884   0   3   0   1   0   0]\n",
      " [  0   0 871   5   2   0   0   0]\n",
      " [  0   0   7 839   3  13  35   0]\n",
      " [  0   0   2   0 848  23   1   0]\n",
      " [  0   5   3  11  12 836  16   0]\n",
      " [  0   1   0  51   3  53 790   0]\n",
      " [  0   0   1   1   0   0   0 841]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  1.00000000 0.99772469 0.99886105       879\n",
      "           2  0.99325843 0.99549550 0.99437570       888\n",
      "           3  0.98418079 0.99202733 0.98808849       878\n",
      "           4  0.92197802 0.93534002 0.92861096       897\n",
      "           5  0.97695853 0.97025172 0.97359357       874\n",
      "           6  0.90183387 0.94677237 0.92375691       883\n",
      "           7  0.93824228 0.87973274 0.90804598       898\n",
      "           8  1.00000000 0.99762752 0.99881235       843\n",
      "\n",
      "    accuracy                      0.96392045      7040\n",
      "   macro avg  0.96455649 0.96437149 0.96426812      7040\n",
      "weighted avg  0.96418482 0.96392045 0.96385404      7040\n",
      "\n",
      "==========================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "c:\\users\\dell\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model-2 : Logistic Regression\n",
      "Accuracy of Model 2 on test set :  97.72999999999999\n",
      "Precision of Model 2 on test set :  97.76\n",
      "Recall of Model 2 on test set :  97.74000000000001\n",
      "F1-score of Model-2 on test set :  97.75\n",
      "Confusion Matrix of Model-2 on test set : \n",
      "[[879   0   0   0   0   0   0   0]\n",
      " [  0 888   0   0   0   0   0   0]\n",
      " [  0   0 869   6   1   2   0   0]\n",
      " [  0   0   6 837   1   3  42   8]\n",
      " [  0   0   0   0 873   1   0   0]\n",
      " [  0   5   6   4   2 856  10   0]\n",
      " [  0   0   0  39   2  21 836   0]\n",
      " [  0   0   0   1   0   0   0 842]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  1.00000000 1.00000000 1.00000000       879\n",
      "           2  0.99440090 1.00000000 0.99719259       888\n",
      "           3  0.98637911 0.98974943 0.98806140       878\n",
      "           4  0.94363021 0.93311037 0.93834081       897\n",
      "           5  0.99317406 0.99885584 0.99600685       874\n",
      "           6  0.96942242 0.96942242 0.96942242       883\n",
      "           7  0.94144144 0.93095768 0.93617021       898\n",
      "           8  0.99058824 0.99881376 0.99468399       843\n",
      "\n",
      "    accuracy                      0.97727273      7040\n",
      "   macro avg  0.97737955 0.97761369 0.97748478      7040\n",
      "weighted avg  0.97713346 0.97727273 0.97719120      7040\n",
      "\n",
      "==========================================================================================================\n",
      "Model-3: Decision Tree \n",
      "Accuracy of Model 3 on test set :  94.87\n",
      "Precision of Model 3 on test set :  94.93\n",
      "Recall of Model 3 on test set :  94.92\n",
      "F1-score of Model-3 on test set :  94.91000000000001\n",
      "Confusion Matrix of Model-3 on test set : \n",
      "[[879   0   0   0   0   0   0   0]\n",
      " [  0 873   3   5   1   5   0   1]\n",
      " [  2   0 861   8   3   2   1   1]\n",
      " [  1   0   8 789   0  11  82   6]\n",
      " [  1   1   8   0 859   2   3   0]\n",
      " [  2  17  17  21  12 790  23   1]\n",
      " [  0   0   0  59   7  33 799   0]\n",
      " [  0   0   0  12   0   1   1 829]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  0.99322034 1.00000000 0.99659864       879\n",
      "           2  0.97979798 0.98310811 0.98145025       888\n",
      "           3  0.95986622 0.98063781 0.97014085       878\n",
      "           4  0.88255034 0.87959866 0.88107203       897\n",
      "           5  0.97392290 0.98283753 0.97835991       874\n",
      "           6  0.93601896 0.89467724 0.91488130       883\n",
      "           7  0.87898790 0.88975501 0.88433868       898\n",
      "           8  0.98926014 0.98339265 0.98631767       843\n",
      "\n",
      "    accuracy                      0.94872159      7040\n",
      "   macro avg  0.94920310 0.94925088 0.94914492      7040\n",
      "weighted avg  0.94865089 0.94872159 0.94860397      7040\n",
      "\n",
      "==========================================================================================================\n",
      "Model-4: Naive Bayes \n",
      "Accuracy of Model 4 on test set :  86.21\n",
      "Precision of Model 4 on test set :  86.35000000000001\n",
      "Recall of Model 4 on test set :  86.09\n",
      "F1-score of Model-4 on test set :  86.03\n",
      "Confusion Matrix of Model-4 on test set : \n",
      "[[855   0  24   0   0   0   0   0]\n",
      " [  0 840   1  30   1  16   0   0]\n",
      " [ 22   1 702  80  56   1   0  16]\n",
      " [  0   1  51 517  15 119 139  55]\n",
      " [  0   2  17   1 823  29   2   0]\n",
      " [  1  16   6  26  28 767  39   0]\n",
      " [  0   0   3  66  31  67 730   1]\n",
      " [  0   0   1   7   0   0   0 835]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  0.97380410 0.97269625 0.97324986       879\n",
      "           2  0.97674419 0.94594595 0.96109840       888\n",
      "           3  0.87204969 0.79954442 0.83422460       878\n",
      "           4  0.71114168 0.57636566 0.63669951       897\n",
      "           5  0.86268344 0.94164760 0.90043764       874\n",
      "           6  0.76776777 0.86862967 0.81509033       883\n",
      "           7  0.80219780 0.81291759 0.80752212       898\n",
      "           8  0.92061742 0.99051008 0.95428571       843\n",
      "\n",
      "    accuracy                      0.86207386      7040\n",
      "   macro avg  0.86087576 0.86353215 0.86032602      7040\n",
      "weighted avg  0.86012141 0.86207386 0.85920961      7040\n",
      "\n",
      "==========================================================================================================\n",
      "Model-5: Random-Forest \n",
      "Accuracy of Model 5 on test set :  98.24000000000001\n",
      "Precision of Model 5 on test set :  98.27\n",
      "Recall of Model 5 on test set :  98.25\n",
      "F1-score of Model-5 on test set :  98.26\n",
      "Confusion Matrix of Model-5 on test set : \n",
      "[[879   0   0   0   0   0   0   0]\n",
      " [  0 888   0   0   0   0   0   0]\n",
      " [  0   0 875   2   0   1   0   0]\n",
      " [  1   0   5 846   0   1  42   2]\n",
      " [  0   0   0   0 873   1   0   0]\n",
      " [  0   2   2   4   3 869   3   0]\n",
      " [  0   0   0  28   3  23 844   0]\n",
      " [  0   0   1   0   0   0   0 842]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  0.99886364 1.00000000 0.99943150       879\n",
      "           2  0.99775281 1.00000000 0.99887514       888\n",
      "           3  0.99093998 0.99658314 0.99375355       878\n",
      "           4  0.96136364 0.94314381 0.95216657       897\n",
      "           5  0.99317406 0.99885584 0.99600685       874\n",
      "           6  0.97094972 0.98414496 0.97750281       883\n",
      "           7  0.94938133 0.93986637 0.94459989       898\n",
      "           8  0.99763033 0.99881376 0.99822170       843\n",
      "\n",
      "    accuracy                      0.98238636      7040\n",
      "   macro avg  0.98250694 0.98267599 0.98256975      7040\n",
      "weighted avg  0.98229029 0.98238636 0.98231633      7040\n",
      "\n",
      "==========================================================================================================\n",
      "[93.31, 12.47, 97.23, 96.66, 17.47, 97.23, 97.67, 86.86, 97.23, 96.61, 97.0, 97.23, 51.349999999999994, 96.73, 97.23, 12.47, 96.73, 97.23, 96.65, 12.47, 96.78, 97.59, 32.68, 96.78, 97.72999999999999, 95.62, 96.78, 96.59, 96.73, 96.78, 53.49, 96.73, 96.78, 12.47, 96.73, 96.78, 97.54, 12.47, 96.59, 97.67, 61.41, 96.59, 97.54, 97.1, 96.59, 96.58, 96.73, 96.59, 53.49, 96.73, 96.59, 12.47, 96.73, 96.59, 97.50999999999999, 17.47, 96.58, 97.49, 86.86, 96.58, 97.34, 97.0, 96.58, 96.58, 96.73, 96.58, 53.49, 96.73, 96.58, 12.47, 96.73, 96.58]\n",
      "(10, 0.01, 'rbf')\n",
      "Model-6: Support Vector Machine \n",
      "Accuracy of Model 6 on test set :  98.95\n",
      "Precision of Model 6 on test set :  98.97\n",
      "Recall of Model 6 on test set :  98.97\n",
      "F1-score of Model-6 on test set :  98.96000000000001\n",
      "Confusion Matrix of Model-6 on test set : \n",
      "[[879   0   0   0   0   0   0   0]\n",
      " [  0 888   0   0   0   0   0   0]\n",
      " [  0   0 878   0   0   0   0   0]\n",
      " [  0   0   2 874   0   1  20   0]\n",
      " [  0   0   0   0 873   1   0   0]\n",
      " [  0   1   0   0   0 878   4   0]\n",
      " [  0   0   0  36   0   8 854   0]\n",
      " [  0   0   1   0   0   0   0 842]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  1.00000000 1.00000000 1.00000000       879\n",
      "           2  0.99887514 1.00000000 0.99943725       888\n",
      "           3  0.99659478 1.00000000 0.99829449       878\n",
      "           4  0.96043956 0.97435897 0.96734920       897\n",
      "           5  1.00000000 0.99885584 0.99942759       874\n",
      "           6  0.98873874 0.99433749 0.99153021       883\n",
      "           7  0.97266515 0.95100223 0.96171171       898\n",
      "           8  1.00000000 0.99881376 0.99940653       843\n",
      "\n",
      "    accuracy                      0.98948864      7040\n",
      "   macro avg  0.98966417 0.98967104 0.98964462      7040\n",
      "weighted avg  0.98949364 0.98948864 0.98946772      7040\n",
      "\n",
      "==========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train=pd.read_excel('cTTD_features_with_Labels/S2/trainset_60.xls')  #reading the xls file into dataframe\n",
    "    validate=pd.read_excel('cTTD_features_with_Labels/S2/validate_20.xls')\n",
    "    test=pd.read_excel('cTTD_features_with_Labels/S2/testset_20.xls')\n",
    "    \n",
    "    x_tr=train.drop(43,axis=1)    #separating the target values\n",
    "    y_tr=train[43]\n",
    "    x_v=validate.drop(43,axis=1)\n",
    "    y_v=validate[43]\n",
    "    x_te=test.drop(43,axis=1)\n",
    "    y_te=test[43]\n",
    "    \n",
    "    x_train=x_tr.to_numpy()        # converting dataframe to numpy array\n",
    "    y_train=y_tr.to_numpy()\n",
    "    x_val=x_v.to_numpy()\n",
    "    y_val=y_v.to_numpy()\n",
    "    x_test=x_te.to_numpy()\n",
    "    y_test=y_te.to_numpy()\n",
    "    \n",
    "    sc=StandardScaler()\n",
    "    x_train=sc.fit_transform(x_train)\n",
    "    x_val=sc.fit_transform(x_val)\n",
    "    x_test=sc.fit_transform(x_test)\n",
    "    \n",
    "    model1(x_train,y_train,x_val,y_val,x_test,y_test)\n",
    "    print(\"==========================================================================================================\")\n",
    "    \n",
    "    model2(x_train,y_train,x_val,y_val,x_test,y_test)\n",
    "    print(\"==========================================================================================================\")\n",
    "    \n",
    "    model3(x_train,y_train,x_val,y_val,x_test,y_test)\n",
    "    print(\"==========================================================================================================\")\n",
    "    \n",
    "    model4(x_train,y_train,x_val,y_val,x_test,y_test)\n",
    "    print(\"==========================================================================================================\")\n",
    "    \n",
    "    model5(x_train,y_train,x_val,y_val,x_test,y_test)\n",
    "    print(\"==========================================================================================================\")\n",
    "    \n",
    "    model6(x_train,y_train,x_val,y_val,x_test,y_test)\n",
    "    print(\"==========================================================================================================\")\n",
    "    \n",
    "    s\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main-objective was to give the results obtained from SVM and SGD Classifier:\n",
    "\n",
    "1. Accuracy from Support Vector Machine = 97\n",
    "2. Accuracy from SGD Method = 94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
