{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all the modules/packages required to complete the given task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier,VotingClassifier,AdaBoostClassifier,GradientBoostingClassifier,StackingClassifier,BaggingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import  GaussianProcessClassifier\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,f1_score,classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model-1 performs the Logistic-Regression on the given task and tuning is done using simple loops and the accuracy comes around 98.25 percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1(x_train,y_train,x_test,y_test):\n",
    "    print(\"Model-1 : Logistic Regression \")\n",
    "    param_grid={'solver':['liblinear','newton-cg','sag'],'max_iter':[10000]}\n",
    "    grid = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='accuracy')\n",
    "    grid.fit(x_train,y_train)\n",
    "    y_test_pred=grid.predict(x_test)\n",
    "    acc_test=round(accuracy_score(y_test_pred,y_test),4)*100\n",
    "    print(\"Accuracy of Model 1 on test set : \",acc_test)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Precision of Model 1 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Recall of Model 1 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"F1-score of Model-1 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])\n",
    "    print(\"Confusion Matrix of Model-1 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n",
    "    return grid.best_params_\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the model-2 which performs the KNearest algorithm.In this model-1,the performance of KNN on the given task is improved Firstly,the datasets is provided with all necessary cleaning and converting to numpy array.I have set a range of values for which ,it will tune the value of k on the validation set such that we can know the value of k whichs performs the best on the validation set.Then we used the best value of k for testing purposes and calculate the accuracy of the model,which comes around 96.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2(x_train,y_train,x_test,y_test):\n",
    "    print(\"Model-2 : K-Nearest Neighbors \")\n",
    "    k_range=[3,7,9,13,15,19,23,25]\n",
    "    param_grid=dict(n_neighbors=k_range)\n",
    "    grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "    grid.fit(x_train,y_train)\n",
    "    y_test_pred=grid.predict(x_test)\n",
    "    acc_t=round(accuracy_score(y_test_pred,y_test),4)*100\n",
    "    print(\"Accuracy of Model 2 on test set : \",acc_t)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Precision of Model 2 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Recall of Model 2 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"F1-score of Model-2 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])\n",
    "    print(\"Confusion Matrix of Model-2 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n",
    "    return grid.best_params_\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine Algorithm is performed onn the given model and accuracy obtained was 99.25 percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model3(x_train,y_train,x_test,y_test):\n",
    "    print(\"Model-3 : Support Vector Machine \")\n",
    "    param_grid={'C':[1,10,100,100],'gamma':['auto',0.1,0.01,0.001],'kernel':['rbf','poly']}\n",
    "    grid = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy')\n",
    "    grid.fit(x_train,y_train)\n",
    "    y_test_pred=grid.predict(x_test)\n",
    "    acc_test=round(accuracy_score(y_test_pred,y_test),4)*100\n",
    "    print(\"Accuracy of Model 3 on test set : \",acc_test)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Precision of Model 3 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Recall of Model 3 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"F1-score of Model-3 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])\n",
    "    print(\"Confusion Matrix of Model-3 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n",
    "    return grid.best_params_\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below model implements the DecisionTree Classification.Here we tune its different parameter and try to get the best parameter by performing holdout validation.Then we used the best parameters of the model on test-set and obtain an accuracy around 95 percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model4(x_train,y_train,x_test,y_test):\n",
    "    print(\"Model-4 : Decision Tree \")\n",
    "    param_grid={'criterion':['gini','entropy'],'max_depth':[5,7,9,13,15,23],'min_samples_leaf':[1,2,5]}\n",
    "    grid = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "    grid.fit(x_train,y_train)\n",
    "    y_test_pred=grid.predict(x_test)\n",
    "    acc_test=round(accuracy_score(y_test_pred,y_test),4)*100\n",
    "    print(\"Accuracy of Model 4 on test set : \",acc_test)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Precision of Model 4 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Recall of Model 4 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"F1-score of Model-4 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])\n",
    "    print(\"Confusion Matrix of Model-4 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n",
    "    return grid.best_params_\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given below function perform the Random Forest Classification on the given data.Hypereparameters are tuned according to the validation set and we test the best parameter on test data so that we can get an accuracy of nearly 98.3 percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model5(x_train,y_train,x_test,y_test):\n",
    "    print(\"Model-5 : Random Forest Classification  \")\n",
    "    param_grid={'n_estimators':[10,50,100,200],'criterion':['gini','entropy'],'max_depth':[5,6,8,13,15,23,25]}\n",
    "    grid = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "    grid.fit(x_train,y_train)\n",
    "    y_test_pred=grid.predict(x_test)\n",
    "    acc_test=round(accuracy_score(y_test_pred,y_test),4)*100\n",
    "    print(\"Accuracy of Model 5 on test set : \",acc_test)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Precision of Model 5 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Recall of Model 5 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"F1-score of Model-5 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])\n",
    "    print(\"Confusion Matrix of Model-5 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n",
    "    return grid.best_params_\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given below function perform the ExtraTrees Classification on the given data.Hypereparameters are tuned according to the validation set and we test the best parameter on test data so that we can get an accuracy more than 98.3 percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model6(x_train,y_train,x_test,y_test):\n",
    "    print(\"Model-6 : ExtraTrees Classification  \")\n",
    "    param_grid={'n_estimators':[10,50,100,200],'criterion':['gini','entropy'],'max_depth':[5,6,8,13,15,23,25]}\n",
    "    grid = GridSearchCV(ExtraTreesClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "    grid.fit(x_train,y_train)\n",
    "    y_test_pred=grid.predict(x_test)\n",
    "    acc_test=round(accuracy_score(y_test_pred,y_test),4)*100\n",
    "    print(\"Accuracy of Model 6 on test set : \",acc_test)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Precision of Model 6 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Recall of Model 6 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"F1-score of Model-6 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])\n",
    "    print(\"Confusion Matrix of Model-6 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n",
    "    return grid.best_params_\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given below is the VotingClassifier which trains on an ensemble of numerous models and predicts an output (class) based on their highest probability of chosen class as the output. It simply aggregates the findings of each classifier passed into Voting Classifier and predicts the output class based on the highest majority of voting. In this hard voting method was used to train the model,the predicted output class was class with highest majority of votes. The accuracy obtained was slightly less than the accuracy obtained from SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model7(x_train,x_test,y_train,y_test,estimator):\n",
    "    e=[('lr',LogisticRegression(solver=estimator[0]['solver'])),\n",
    "       ('knn',KNeighborsClassifier(n_neighbors=estimator[1]['n_neighbors'])),\n",
    "      ('svm',SVC(C=estimator[2]['C'],gamma=estimator[2]['gamma'],kernel='rbf')),\n",
    "      ('dt',DecisionTreeClassifier(criterion=estimator[3]['criterion'],max_depth=estimator[3]['max_depth'])),\n",
    "      ('rf',RandomForestClassifier(n_estimators=estimator[4]['n_estimators'],criterion=estimator[4]['criterion'],max_depth=estimator[4]['max_depth'])),\n",
    "      ('et',ExtraTreesClassifier(n_estimators=estimator[5]['n_estimators'],criterion=estimator[5]['criterion'],max_depth=estimator[5]['max_depth']))]\n",
    "    print(\"Model-7 : VotingClassifier\")\n",
    "    vot_hard=VotingClassifier(estimators = e, voting ='hard') \n",
    "    vot_hard.fit(x_train, y_train)\n",
    "    y_test_pred=vot_hard.predict(x_test)\n",
    "    acc_t=round(accuracy_score(y_test_pred,y_test),4)*100    #accuracy of the predicting model\n",
    "    print(\"Accuracy of Model 7 on test set : \",acc_t)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100   #precision of the predicting model\n",
    "    print(\"Precision of Model 7 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100      #recall_Score of the model\n",
    "    print(\"Recall of Model 7 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100      #f1_score of the model\n",
    "    print(\"F1-score of Model-7 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])   #confusion matrix of the model\n",
    "    print(\"Confusion Matrix of Model-7 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Bagging classifier is an ensemble meta-estimator that fits base classifiers each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. Such a meta-estimator can typically be used as a way to reduce the variance of a black-box estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it.\n",
    "\n",
    "The accuracy obtained was greater than 98.98 percent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model8(x_train,x_test,y_train,y_test,estimator):\n",
    "    print(\"Model-8 : BaggingClassifier\")\n",
    "    bag=BaggingClassifier(base_estimator=SVC(C=estimator[2]['C'],gamma=estimator[2]['gamma'],kernel='rbf'),n_estimators=200,random_state=5) \n",
    "    bag.fit(x_train, y_train)\n",
    "    y_test_pred=bag.predict(x_test)\n",
    "    acc_t=round(accuracy_score(y_test_pred,y_test),4)*100    #accuracy of the predicting model\n",
    "    print(\"Accuracy of Model 8 on test set : \",acc_t)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100   #precision of the predicting model\n",
    "    print(\"Precision of Model 8 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100      #recall_Score of the model\n",
    "    print(\"Recall of Model 8 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100      #f1_score of the model\n",
    "    print(\"F1-score of Model-8 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])   #confusion matrix of the model\n",
    "    print(\"Confusion Matrix of Model-8 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the boosting method in which I have used GradientBoosting and obtain an accuracy around 98.5 percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model9(x_train,x_test,y_train,y_test,estimator):\n",
    "    print(\"Model-9 Gradient-Boosting \")\n",
    "    gbc=GradientBoostingClassifier(n_estimators=200,learning_rate=0.1,subsample=1,random_state=0)\n",
    "    gbc.fit(x_train,y_train)\n",
    "    y_test_pred=gbc.predict(x_test)\n",
    "    acc_t=round(accuracy_score(y_test_pred,y_test),4)*100    #accuracy of the predicting model\n",
    "    print(\"Accuracy of Model 9 on test set : \",acc_t)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100   #precision of the predicting model\n",
    "    print(\"Precision of Model 9 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100      #recall_Score of the model\n",
    "    print(\"Recall of Model 9 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100      #f1_score of the model\n",
    "    print(\"F1-score of Model-9 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])   #confusion matrix of the model\n",
    "    print(\"Confusion Matrix of Model-9 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the implementation of StackingClassifier.Here,we stacked the results obtain from different classifier and stacked together and passed to a final classifier which is SVM and the result obtained was around 99.3 percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model10(x_train,x_test,y_train,y_test,estimator):\n",
    "    esti=[('lr',LogisticRegression(solver=estimator[0]['solver'])),\n",
    "          ('knn',KNeighborsClassifier(n_neighbors=estimator[1]['n_neighbors'])),\n",
    "          ('svm',SVC(C=estimator[2]['C'],gamma=estimator[2]['gamma'],kernel='rbf')),\n",
    "          ('dt',DecisionTreeClassifier(criterion=estimator[3]['criterion'],max_depth=estimator[3]['max_depth'])),\n",
    "          ('rf',RandomForestClassifier(n_estimators=estimator[4]['n_estimators'],criterion=estimator[4]['criterion'],max_depth=estimator[4]['max_depth'])),\n",
    "          ('et',ExtraTreesClassifier(n_estimators=estimator[5]['n_estimators'],criterion=estimator[5]['criterion'],max_depth=estimator[5]['max_depth']))]\n",
    "    print(\"Model-10 : Stacking Classifier \")\n",
    "    stc=StackingClassifier(estimators=esti,final_estimator=SVC(C=estimator[2]['C'],gamma=estimator[2]['gamma'],kernel='rbf'),cv=3)\n",
    "    stc.fit(x_train,y_train)\n",
    "    y_test_pred=stc.predict(x_test)\n",
    "    acc_t=round(accuracy_score(y_test_pred,y_test),4)*100    #accuracy of the predicting model\n",
    "    print(\"Accuracy of Model 10 on test set : \",acc_t)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100   #precision of the predicting model\n",
    "    print(\"Precision of Model 10 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100      #recall_Score of the model\n",
    "    print(\"Recall of Model 10 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100      #f1_score of the model\n",
    "    print(\"F1-score of Model-10 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])   #confusion matrix of the model\n",
    "    print(\"Confusion Matrix of Model-10 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model-1 : Logistic Regression \n",
      "Accuracy of Model 1 on test set :  98.24000000000001\n",
      "Precision of Model 1 on test set :  98.26\n",
      "Recall of Model 1 on test set :  98.26\n",
      "F1-score of Model-1 on test set :  98.26\n",
      "Confusion Matrix of Model-1 on test set : \n",
      "[[879   0   0   0   0   0   0   0]\n",
      " [  0 888   0   0   0   0   0   0]\n",
      " [  0   0 874   2   0   2   0   0]\n",
      " [  0   0   5 855   0   1  32   4]\n",
      " [  0   0   0   0 873   1   0   0]\n",
      " [  0   3   2   1   1 869   7   0]\n",
      " [  0   0   0  46   1  11 840   0]\n",
      " [  0   0   3   0   0   0   2 838]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  1.00000000 1.00000000 1.00000000       879\n",
      "           2  0.99663300 1.00000000 0.99831366       888\n",
      "           3  0.98868778 0.99544419 0.99205448       878\n",
      "           4  0.94579646 0.95317726 0.94947252       897\n",
      "           5  0.99771429 0.99885584 0.99828473       874\n",
      "           6  0.98303167 0.98414496 0.98358800       883\n",
      "           7  0.95346198 0.93541203 0.94435076       898\n",
      "           8  0.99524941 0.99406880 0.99465875       843\n",
      "\n",
      "    accuracy                      0.98238636      7040\n",
      "   macro avg  0.98257182 0.98263788 0.98259036      7040\n",
      "weighted avg  0.98234102 0.98238636 0.98234895      7040\n",
      "\n",
      "==========================================================================================================\n",
      "Model-2 : K-Nearest Neighbors \n",
      "Accuracy of Model 2 on test set :  96.96000000000001\n",
      "Precision of Model 2 on test set :  97.0\n",
      "Recall of Model 2 on test set :  97.00999999999999\n",
      "F1-score of Model-2 on test set :  96.99\n",
      "Confusion Matrix of Model-2 on test set : \n",
      "[[876   0   1   0   2   0   0   0]\n",
      " [  0 888   0   0   0   0   0   0]\n",
      " [  0   0 873   5   0   0   0   0]\n",
      " [  0   0  10 849   1   4  33   0]\n",
      " [  0   1   1   2 857  13   0   0]\n",
      " [  0   9   2  16   7 840   9   0]\n",
      " [  0   0   0  51   2  44 801   0]\n",
      " [  0   0   0   1   0   0   0 842]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  1.00000000 0.99658703 0.99829060       879\n",
      "           2  0.98886414 1.00000000 0.99440090       888\n",
      "           3  0.98421646 0.99430524 0.98923513       878\n",
      "           4  0.91883117 0.94648829 0.93245470       897\n",
      "           5  0.98619102 0.98054920 0.98336202       874\n",
      "           6  0.93229745 0.95130238 0.94170404       883\n",
      "           7  0.95017794 0.89198218 0.92016083       898\n",
      "           8  1.00000000 0.99881376 0.99940653       843\n",
      "\n",
      "    accuracy                      0.96960227      7040\n",
      "   macro avg  0.97007227 0.97000351 0.96987684      7040\n",
      "weighted avg  0.96972363 0.96960227 0.96949900      7040\n",
      "\n",
      "==========================================================================================================\n",
      "Model-3 : Support Vector Machine \n",
      "Accuracy of Model 3 on test set :  99.22\n",
      "Precision of Model 3 on test set :  99.22999999999999\n",
      "Recall of Model 3 on test set :  99.24\n",
      "F1-score of Model-3 on test set :  99.22999999999999\n",
      "Confusion Matrix of Model-3 on test set : \n",
      "[[879   0   0   0   0   0   0   0]\n",
      " [  0 888   0   0   0   0   0   0]\n",
      " [  0   0 878   0   0   0   0   0]\n",
      " [  0   0   1 884   0   0  12   0]\n",
      " [  0   0   0   0 873   1   0   0]\n",
      " [  0   0   0   0   0 881   2   0]\n",
      " [  0   0   0  30   0   7 861   0]\n",
      " [  0   0   1   1   0   0   0 841]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  1.00000000 1.00000000 1.00000000       879\n",
      "           2  1.00000000 1.00000000 1.00000000       888\n",
      "           3  0.99772727 1.00000000 0.99886234       878\n",
      "           4  0.96612022 0.98550725 0.97571744       897\n",
      "           5  1.00000000 0.99885584 0.99942759       874\n",
      "           6  0.99100112 0.99773499 0.99435666       883\n",
      "           7  0.98400000 0.95879733 0.97123519       898\n",
      "           8  1.00000000 0.99762752 0.99881235       843\n",
      "\n",
      "    accuracy                      0.99218750      7040\n",
      "   macro avg  0.99235608 0.99231537 0.99230145      7040\n",
      "weighted avg  0.99223017 0.99218750 0.99217391      7040\n",
      "\n",
      "==========================================================================================================\n",
      "Model-4 : Decision Tree \n",
      "Accuracy of Model 4 on test set :  94.43\n",
      "Precision of Model 4 on test set :  94.49\n",
      "Recall of Model 4 on test set :  94.47\n",
      "F1-score of Model-4 on test set :  94.48\n",
      "Confusion Matrix of Model-4 on test set : \n",
      "[[876   0   2   1   0   0   0   0]\n",
      " [  0 871   4   5   0   8   0   0]\n",
      " [  4   0 861   8   2   2   0   1]\n",
      " [  3   1  12 775   0  10  89   7]\n",
      " [  2   1   5   1 862   1   2   0]\n",
      " [  3  14  15  22  11 795  23   0]\n",
      " [  0   3   0  67   7  41 780   0]\n",
      " [  0   1   0  14   0   0   0 828]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  0.98648649 0.99658703 0.99151104       879\n",
      "           2  0.97755331 0.98085586 0.97920180       888\n",
      "           3  0.95773081 0.98063781 0.96904896       878\n",
      "           4  0.86786114 0.86399108 0.86592179       897\n",
      "           5  0.97732426 0.98627002 0.98177677       874\n",
      "           6  0.92765461 0.90033975 0.91379310       883\n",
      "           7  0.87248322 0.86859688 0.87053571       898\n",
      "           8  0.99043062 0.98220641 0.98630137       843\n",
      "\n",
      "    accuracy                      0.94431818      7040\n",
      "   macro avg  0.94469056 0.94493561 0.94476132      7040\n",
      "weighted avg  0.94407265 0.94431818 0.94414369      7040\n",
      "\n",
      "==========================================================================================================\n",
      "Model-5 : Random Forest Classification  \n",
      "Accuracy of Model 5 on test set :  98.44000000000001\n",
      "Precision of Model 5 on test set :  98.46000000000001\n",
      "Recall of Model 5 on test set :  98.45\n",
      "F1-score of Model-5 on test set :  98.46000000000001\n",
      "Confusion Matrix of Model-5 on test set : \n",
      "[[879   0   0   0   0   0   0   0]\n",
      " [  0 888   0   0   0   0   0   0]\n",
      " [  0   0 876   2   0   0   0   0]\n",
      " [  1   0   5 851   0   1  38   1]\n",
      " [  0   0   0   0 873   1   0   0]\n",
      " [  0   2   2   1   2 873   3   0]\n",
      " [  0   0   0  29   1  21 847   0]\n",
      " [  0   0   0   0   0   0   0 843]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  0.99886364 1.00000000 0.99943150       879\n",
      "           2  0.99775281 1.00000000 0.99887514       888\n",
      "           3  0.99207248 0.99772210 0.99488927       878\n",
      "           4  0.96375991 0.94871795 0.95617978       897\n",
      "           5  0.99657534 0.99885584 0.99771429       874\n",
      "           6  0.97433036 0.98867497 0.98145025       883\n",
      "           7  0.95382883 0.94320713 0.94848824       898\n",
      "           8  0.99881517 1.00000000 0.99940723       843\n",
      "\n",
      "    accuracy                      0.98437500      7040\n",
      "   macro avg  0.98449982 0.98464725 0.98455446      7040\n",
      "weighted avg  0.98429232 0.98437500 0.98431435      7040\n",
      "\n",
      "==========================================================================================================\n",
      "Model-6 : ExtraTrees Classification  \n",
      "Accuracy of Model 6 on test set :  98.38\n",
      "Precision of Model 6 on test set :  98.41\n",
      "Recall of Model 6 on test set :  98.4\n",
      "F1-score of Model-6 on test set :  98.4\n",
      "Confusion Matrix of Model-6 on test set : \n",
      "[[879   0   0   0   0   0   0   0]\n",
      " [  0 888   0   0   0   0   0   0]\n",
      " [  0   0 876   2   0   0   0   0]\n",
      " [  0   0   6 848   2   0  41   0]\n",
      " [  0   0   0   0 874   0   0   0]\n",
      " [  0   1   3   2   0 872   5   0]\n",
      " [  0   0   0  29   2  21 846   0]\n",
      " [  0   0   0   0   0   0   0 843]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  1.00000000 1.00000000 1.00000000       879\n",
      "           2  0.99887514 1.00000000 0.99943725       888\n",
      "           3  0.98983051 0.99772210 0.99376064       878\n",
      "           4  0.96254257 0.94537347 0.95388076       897\n",
      "           5  0.99544419 1.00000000 0.99771689       874\n",
      "           6  0.97648376 0.98754247 0.98198198       883\n",
      "           7  0.94843049 0.94209354 0.94525140       898\n",
      "           8  1.00000000 1.00000000 1.00000000       843\n",
      "\n",
      "    accuracy                      0.98380682      7040\n",
      "   macro avg  0.98395083 0.98409145 0.98400362      7040\n",
      "weighted avg  0.98372400 0.98380682 0.98374767      7040\n",
      "\n",
      "==========================================================================================================\n",
      "[{'max_iter': 10000, 'solver': 'newton-cg'}, {'n_neighbors': 3}, {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_leaf': 2}, {'criterion': 'entropy', 'max_depth': 25, 'n_estimators': 200}, {'criterion': 'entropy', 'max_depth': 25, 'n_estimators': 200}]\n",
      "Model-7 : VotingClassifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model 7 on test set :  98.81\n",
      "Precision of Model 7 on test set :  98.83\n",
      "Recall of Model 7 on test set :  98.82\n",
      "F1-score of Model-7 on test set :  98.82\n",
      "Confusion Matrix of Model-7 on test set : \n",
      "[[879   0   0   0   0   0   0   0]\n",
      " [  0 888   0   0   0   0   0   0]\n",
      " [  0   0 878   0   0   0   0   0]\n",
      " [  0   0   5 873   0   0  19   0]\n",
      " [  0   0   0   0 873   1   0   0]\n",
      " [  0   1   2   1   0 876   3   0]\n",
      " [  0   0   0  32   1  19 846   0]\n",
      " [  0   0   0   0   0   0   0 843]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  1.00000000 1.00000000 1.00000000       879\n",
      "           2  0.99887514 1.00000000 0.99943725       888\n",
      "           3  0.99209040 1.00000000 0.99602950       878\n",
      "           4  0.96357616 0.97324415 0.96838602       897\n",
      "           5  0.99885584 0.99885584 0.99885584       874\n",
      "           6  0.97767857 0.99207248 0.98482293       883\n",
      "           7  0.97465438 0.94209354 0.95809740       898\n",
      "           8  1.00000000 1.00000000 1.00000000       843\n",
      "\n",
      "    accuracy                      0.98806818      7040\n",
      "   macro avg  0.98821631 0.98828325 0.98820362      7040\n",
      "weighted avg  0.98805598 0.98806818 0.98801514      7040\n",
      "\n",
      "===========================================================================================================\n",
      "Model-8 : BaggingClassifier\n",
      "Accuracy of Model 8 on test set :  99.11999999999999\n",
      "Precision of Model 8 on test set :  99.13\n",
      "Recall of Model 8 on test set :  99.14\n",
      "F1-score of Model-8 on test set :  99.13\n",
      "Confusion Matrix of Model-8 on test set : \n",
      "[[879   0   0   0   0   0   0   0]\n",
      " [  0 888   0   0   0   0   0   0]\n",
      " [  0   0 878   0   0   0   0   0]\n",
      " [  0   0   2 880   0   1  14   0]\n",
      " [  0   0   0   0 873   1   0   0]\n",
      " [  0   0   0   0   0 880   3   0]\n",
      " [  0   0   0  32   0   8 858   0]\n",
      " [  0   0   1   0   0   0   0 842]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  1.00000000 1.00000000 1.00000000       879\n",
      "           2  1.00000000 1.00000000 1.00000000       888\n",
      "           3  0.99659478 1.00000000 0.99829449       878\n",
      "           4  0.96491228 0.98104794 0.97291321       897\n",
      "           5  1.00000000 0.99885584 0.99942759       874\n",
      "           6  0.98876404 0.99660249 0.99266779       883\n",
      "           7  0.98057143 0.95545657 0.96785110       898\n",
      "           8  1.00000000 0.99881376 0.99940653       843\n",
      "\n",
      "    accuracy                      0.99119318      7040\n",
      "   macro avg  0.99135532 0.99134707 0.99132009      7040\n",
      "weighted avg  0.99121709 0.99119318 0.99117345      7040\n",
      "\n",
      "===========================================================================================================\n",
      "Model-9 Gradient-Boosting \n",
      "Accuracy of Model 9 on test set :  98.54\n",
      "Precision of Model 9 on test set :  98.56\n",
      "Recall of Model 9 on test set :  98.56\n",
      "F1-score of Model-9 on test set :  98.56\n",
      "Confusion Matrix of Model-9 on test set : \n",
      "[[879   0   0   0   0   0   0   0]\n",
      " [  0 885   0   2   0   0   1   0]\n",
      " [  0   0 875   2   0   1   0   0]\n",
      " [  0   0   3 868   0   0  24   2]\n",
      " [  0   0   0   0 874   0   0   0]\n",
      " [  0   2   0   3   2 871   5   0]\n",
      " [  0   0   0  37   1  16 844   0]\n",
      " [  0   0   0   1   1   0   0 841]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  1.00000000 1.00000000 1.00000000       879\n",
      "           2  0.99774521 0.99662162 0.99718310       888\n",
      "           3  0.99658314 0.99658314 0.99658314       878\n",
      "           4  0.95071194 0.96767001 0.95911602       897\n",
      "           5  0.99544419 1.00000000 0.99771689       874\n",
      "           6  0.98085586 0.98640997 0.98362507       883\n",
      "           7  0.96567506 0.93986637 0.95259594       898\n",
      "           8  0.99762752 0.99762752 0.99762752       843\n",
      "\n",
      "    accuracy                      0.98536932      7040\n",
      "   macro avg  0.98558036 0.98559733 0.98555596      7040\n",
      "weighted avg  0.98538018 0.98536932 0.98534124      7040\n",
      "\n",
      "===========================================================================================================\n",
      "Model-10 : Stacking Classifier \n",
      "Accuracy of Model 10 on test set :  99.28\n",
      "Precision of Model 10 on test set :  99.29\n",
      "Recall of Model 10 on test set :  99.29\n",
      "F1-score of Model-10 on test set :  99.29\n",
      "Confusion Matrix of Model-10 on test set : \n",
      "[[879   0   0   0   0   0   0   0]\n",
      " [  0 888   0   0   0   0   0   0]\n",
      " [  0   0 878   0   0   0   0   0]\n",
      " [  0   0   1 882   0   0  14   0]\n",
      " [  0   0   0   0 873   1   0   0]\n",
      " [  0   0   0   0   0 881   2   0]\n",
      " [  0   0   0  26   0   7 865   0]\n",
      " [  0   0   0   0   0   0   0 843]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  1.00000000 1.00000000 1.00000000       879\n",
      "           2  1.00000000 1.00000000 1.00000000       888\n",
      "           3  0.99886234 1.00000000 0.99943085       878\n",
      "           4  0.97136564 0.98327759 0.97728532       897\n",
      "           5  1.00000000 0.99885584 0.99942759       874\n",
      "           6  0.99100112 0.99773499 0.99435666       883\n",
      "           7  0.98183882 0.96325167 0.97245644       898\n",
      "           8  1.00000000 1.00000000 1.00000000       843\n",
      "\n",
      "    accuracy                      0.99275568      7040\n",
      "   macro avg  0.99288349 0.99289001 0.99286961      7040\n",
      "weighted avg  0.99276440 0.99275568 0.99274258      7040\n",
      "\n",
      "===========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train=pd.read_excel('cTTD_features_with_Labels/S2/trainset_60.xls')  #reading the xls file into dataframe\n",
    "    validate=pd.read_excel('cTTD_features_with_Labels/S2/validate_20.xls')\n",
    "    test=pd.read_excel('cTTD_features_with_Labels/S2/testset_20.xls')\n",
    "    \n",
    "    x_tr=train.drop(43,axis=1)    #separating the target values\n",
    "    y_tr=train[43]\n",
    "    x_v=validate.drop(43,axis=1)\n",
    "    y_v=validate[43]\n",
    "    x_te=test.drop(43,axis=1)\n",
    "    y_te=test[43]\n",
    "    \n",
    "    x_train=x_tr.to_numpy()        # converting dataframe to numpy array\n",
    "    y_train=y_tr.to_numpy()\n",
    "    x_val=x_v.to_numpy()\n",
    "    y_val=y_v.to_numpy()\n",
    "    x_test=x_te.to_numpy()\n",
    "    y_test=y_te.to_numpy()\n",
    "    \n",
    "    sc=StandardScaler()\n",
    "    x_train=sc.fit_transform(x_train)       #standardizing the features for better traing process\n",
    "    x_val=sc.fit_transform(x_val)\n",
    "    x_test=sc.fit_transform(x_test)\n",
    "    estimator=[]\n",
    "    \n",
    "    x_train=np.concatenate((x_train,x_val))  #Now combining both training and validation data\n",
    "    y_train=np.concatenate((y_train,y_val))  #Now combing the target values of training and validation data\n",
    "    \n",
    "    \n",
    "    estimator.append(model1(x_train,y_train,x_test,y_test))\n",
    "    print(\"==========================================================================================================\")\n",
    "    \n",
    "    estimator.append(model2(x_train,y_train,x_test,y_test))\n",
    "    print(\"==========================================================================================================\")\n",
    "    \n",
    "    \n",
    "    estimator.append(model3(x_train,y_train,x_test,y_test))\n",
    "    print(\"==========================================================================================================\")\n",
    "    \n",
    "    estimator.append(model4(x_train,y_train,x_test,y_test))\n",
    "    print(\"==========================================================================================================\")\n",
    "    \n",
    "    \n",
    "    estimator.append(model5(x_train,y_train,x_test,y_test))\n",
    "    print(\"==========================================================================================================\")\n",
    "    \n",
    "    estimator.append(model6(x_train,y_train,x_test,y_test))\n",
    "    print(\"==========================================================================================================\")\n",
    "    \n",
    "    print(estimator)\n",
    "    \n",
    "   \n",
    "    model7(x_train,x_test,y_train,y_test,estimator)\n",
    "    print(\"===========================================================================================================\")\n",
    "    \n",
    "    model8(x_train,x_test,y_train,y_test,estimator)\n",
    "    print(\"===========================================================================================================\")\n",
    "    \n",
    "    model9(x_train,x_test,y_train,y_test,estimator)\n",
    "    print(\"===========================================================================================================\")\n",
    "    \n",
    "    model10(x_train,x_test,y_train,y_test,estimator)\n",
    "    print(\"===========================================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
