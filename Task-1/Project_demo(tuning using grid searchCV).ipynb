{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, the aim of the task is to share the results (accuracy score/performance) of two machine learning model i.e Support Vector Machine and Stochastic Gradient Descent Method.But,I have used many other classification algorithms to see which performs the best among all the algorithms.\n",
    "The datasets was provided to perform the task.It was boardly divided such that 60% of data was for training the model,20% of data was to validate the model such that we can tune its hyperparameters and its performance is improved and the rest 20% was for testing purpose.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import  GaussianProcessClassifier\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,f1_score,classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1(x_train,y_train,x_test,y_test):\n",
    "    k_range=[3,7,9,13,15,19,23,25]\n",
    "    param_grid=dict(n_neighbors=k_range)\n",
    "    grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "    grid.fit(x_train,y_train)\n",
    "    print(\"Model-1 : K-Nearest Neighbors \")\n",
    "    y_test_pred=grid.predict(x_test)\n",
    "    acc_t=round(accuracy_score(y_test_pred,y_test),4)*100\n",
    "    print(\"Accuracy of Model 1 on test set : \",acc_t)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Precision of Model 1 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Recall of Model 1 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"F1-score of Model-1 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])\n",
    "    print(\"Confusion Matrix of Model-1 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n",
    "    return grid.best_params_\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2(x_train,y_train,x_test,y_test):\n",
    "    param_grid={'solver':['liblinear','newton-cg','sag'],'max_iter':[10000]}\n",
    "    grid = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='accuracy')\n",
    "    grid.fit(x_train,y_train)\n",
    "    print(\"Model-2 : Logistic Regression \")\n",
    "    y_test_pred=grid.predict(x_test)\n",
    "    acc_test=round(accuracy_score(y_test_pred,y_test),4)*100\n",
    "    print(\"Accuracy of Model 2 on test set : \",acc_test)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Precision of Model 2 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Recall of Model 2 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"F1-score of Model-2 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])\n",
    "    print(\"Confusion Matrix of Model-2 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n",
    "    return grid.best_params_\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model3(x_train,y_train,x_test,y_test):\n",
    "    param_grid={'criterion':['gini','entropy'],'max_depth':[5,7,9,13,15,23],'min_samples_leaf':[1,2,5]}\n",
    "    grid = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "    grid.fit(x_train,y_train)\n",
    "    print(\"Model-3 : Decision Tree \")\n",
    "    y_test_pred=grid.predict(x_test)\n",
    "    acc_test=round(accuracy_score(y_test_pred,y_test),4)*100\n",
    "    print(\"Accuracy of Model 3 on test set : \",acc_test)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Precision of Model 3 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Recall of Model 3 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"F1-score of Model-3 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])\n",
    "    print(\"Confusion Matrix of Model-3 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n",
    "    return grid.best_params_\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model5(x_train,y_train,x_test,y_test):\n",
    "    param_grid={'n_estimators':[1,10,20,50,100],'criterion':['gini','entropy'],'max_depth':[5,6,8,13,15,23,25]}\n",
    "    grid = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "    grid.fit(x_train,y_train)\n",
    "    print(\"Model-5 : Random Forest Classification  \")\n",
    "    y_test_pred=grid.predict(x_test)\n",
    "    acc_test=round(accuracy_score(y_test_pred,y_test),4)*100\n",
    "    print(\"Accuracy of Model 5 on test set : \",acc_test)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Precision of Model 5 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Recall of Model 5 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"F1-score of Model-5 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])\n",
    "    print(\"Confusion Matrix of Model-5 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n",
    "    return grid.best_params_\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model6(x_train,y_train,x_test,y_test):\n",
    "    param_grid={'C':[1,10,100,100],'gamma':['auto',0.1,0.01,0.001],'kernel':['rbf','poly']}\n",
    "    grid = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy')\n",
    "    grid.fit(x_train,y_train)\n",
    "    print(\"Model-6 : Support Vector Machine  \")\n",
    "    y_test_pred=grid.predict(x_test)\n",
    "    acc_test=round(accuracy_score(y_test_pred,y_test),4)*100\n",
    "    print(\"Accuracy of Model 6 on test set : \",acc_test)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Precision of Model 6 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Recall of Model 6 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"F1-score of Model-6 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])\n",
    "    print(\"Confusion Matrix of Model-6 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n",
    "    return grid.best_params_\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model-1 : K-Nearest Neighbors \n",
      "Accuracy of Model 1 on test set :  96.96000000000001\n",
      "Precision of Model 1 on test set :  97.0\n",
      "Recall of Model 1 on test set :  97.00999999999999\n",
      "F1-score of Model-1 on test set :  96.99\n",
      "Confusion Matrix of Model-1 on test set : \n",
      "[[876   0   1   0   2   0   0   0]\n",
      " [  0 888   0   0   0   0   0   0]\n",
      " [  0   0 873   5   0   0   0   0]\n",
      " [  0   0  10 849   1   4  33   0]\n",
      " [  0   1   1   2 857  13   0   0]\n",
      " [  0   9   2  16   7 840   9   0]\n",
      " [  0   0   0  51   2  44 801   0]\n",
      " [  0   0   0   1   0   0   0 842]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  1.00000000 0.99658703 0.99829060       879\n",
      "           2  0.98886414 1.00000000 0.99440090       888\n",
      "           3  0.98421646 0.99430524 0.98923513       878\n",
      "           4  0.91883117 0.94648829 0.93245470       897\n",
      "           5  0.98619102 0.98054920 0.98336202       874\n",
      "           6  0.93229745 0.95130238 0.94170404       883\n",
      "           7  0.95017794 0.89198218 0.92016083       898\n",
      "           8  1.00000000 0.99881376 0.99940653       843\n",
      "\n",
      "    accuracy                      0.96960227      7040\n",
      "   macro avg  0.97007227 0.97000351 0.96987684      7040\n",
      "weighted avg  0.96972363 0.96960227 0.96949900      7040\n",
      "\n",
      "==========================================================================================================\n",
      "Model-2 : Logistic Regression \n",
      "Accuracy of Model 2 on test set :  98.24000000000001\n",
      "Precision of Model 2 on test set :  98.26\n",
      "Recall of Model 2 on test set :  98.26\n",
      "F1-score of Model-2 on test set :  98.26\n",
      "Confusion Matrix of Model-2 on test set : \n",
      "[[879   0   0   0   0   0   0   0]\n",
      " [  0 888   0   0   0   0   0   0]\n",
      " [  0   0 874   2   0   2   0   0]\n",
      " [  0   0   5 855   0   1  32   4]\n",
      " [  0   0   0   0 873   1   0   0]\n",
      " [  0   3   2   1   1 869   7   0]\n",
      " [  0   0   0  46   1  11 840   0]\n",
      " [  0   0   3   0   0   0   2 838]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  1.00000000 1.00000000 1.00000000       879\n",
      "           2  0.99663300 1.00000000 0.99831366       888\n",
      "           3  0.98868778 0.99544419 0.99205448       878\n",
      "           4  0.94579646 0.95317726 0.94947252       897\n",
      "           5  0.99771429 0.99885584 0.99828473       874\n",
      "           6  0.98303167 0.98414496 0.98358800       883\n",
      "           7  0.95346198 0.93541203 0.94435076       898\n",
      "           8  0.99524941 0.99406880 0.99465875       843\n",
      "\n",
      "    accuracy                      0.98238636      7040\n",
      "   macro avg  0.98257182 0.98263788 0.98259036      7040\n",
      "weighted avg  0.98234102 0.98238636 0.98234895      7040\n",
      "\n",
      "==========================================================================================================\n",
      "Model-3 : Decision Tree \n",
      "Accuracy of Model 3 on test set :  94.86\n",
      "Precision of Model 3 on test set :  94.92\n",
      "Recall of Model 3 on test set :  94.89\n",
      "F1-score of Model-3 on test set :  94.89\n",
      "Confusion Matrix of Model-3 on test set : \n",
      "[[871   0   4   1   3   0   0   0]\n",
      " [  0 875   4   4   1   4   0   0]\n",
      " [  2   1 867   5   2   1   0   0]\n",
      " [  3   0   8 777   1  10  91   7]\n",
      " [  2   1   4   1 862   3   1   0]\n",
      " [  2  19  16  20  10 796  20   0]\n",
      " [  0   1   0  54   8  36 799   0]\n",
      " [  0   0   1   9   0   0   2 831]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  0.98977273 0.99089875 0.99033542       879\n",
      "           2  0.97547380 0.98536036 0.98039216       888\n",
      "           3  0.95907080 0.98747153 0.97306397       878\n",
      "           4  0.89207807 0.86622074 0.87895928       897\n",
      "           5  0.97181511 0.98627002 0.97898921       874\n",
      "           6  0.93647059 0.90147225 0.91863820       883\n",
      "           7  0.87513691 0.88975501 0.88238542       898\n",
      "           8  0.99164678 0.98576512 0.98869720       843\n",
      "\n",
      "    accuracy                      0.94857955      7040\n",
      "   macro avg  0.94893310 0.94915172 0.94893261      7040\n",
      "weighted avg  0.94837930 0.94857955 0.94836899      7040\n",
      "\n",
      "==========================================================================================================\n",
      "Model-5 : Random Forest Classification  \n",
      "Accuracy of Model 5 on test set :  98.25\n",
      "Precision of Model 5 on test set :  98.28\n",
      "Recall of Model 5 on test set :  98.27\n",
      "F1-score of Model-5 on test set :  98.27\n",
      "Confusion Matrix of Model-5 on test set : \n",
      "[[879   0   0   0   0   0   0   0]\n",
      " [  0 888   0   0   0   0   0   0]\n",
      " [  0   0 876   2   0   0   0   0]\n",
      " [  0   0   6 846   0   2  42   1]\n",
      " [  0   0   0   0 873   1   0   0]\n",
      " [  0   4   1   3   2 868   5   0]\n",
      " [  0   0   0  30   1  23 844   0]\n",
      " [  0   0   0   0   0   0   0 843]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  1.00000000 1.00000000 1.00000000       879\n",
      "           2  0.99551570 1.00000000 0.99775281       888\n",
      "           3  0.99207248 0.99772210 0.99488927       878\n",
      "           4  0.96027242 0.94314381 0.95163105       897\n",
      "           5  0.99657534 0.99885584 0.99771429       874\n",
      "           6  0.97091723 0.98301246 0.97692741       883\n",
      "           7  0.94725028 0.93986637 0.94354388       898\n",
      "           8  0.99881517 1.00000000 0.99940723       843\n",
      "\n",
      "    accuracy                      0.98252841      7040\n",
      "   macro avg  0.98267733 0.98282507 0.98273324      7040\n",
      "weighted avg  0.98244043 0.98252841 0.98246622      7040\n",
      "\n",
      "==========================================================================================================\n",
      "Model-6 : Support Vector Machine  \n",
      "Accuracy of Model 6 on test set :  99.22\n",
      "Precision of Model 6 on test set :  99.22999999999999\n",
      "Recall of Model 6 on test set :  99.24\n",
      "F1-score of Model-6 on test set :  99.22999999999999\n",
      "Confusion Matrix of Model-6 on test set : \n",
      "[[879   0   0   0   0   0   0   0]\n",
      " [  0 888   0   0   0   0   0   0]\n",
      " [  0   0 878   0   0   0   0   0]\n",
      " [  0   0   1 884   0   0  12   0]\n",
      " [  0   0   0   0 873   1   0   0]\n",
      " [  0   0   0   0   0 881   2   0]\n",
      " [  0   0   0  30   0   7 861   0]\n",
      " [  0   0   1   1   0   0   0 841]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  1.00000000 1.00000000 1.00000000       879\n",
      "           2  1.00000000 1.00000000 1.00000000       888\n",
      "           3  0.99772727 1.00000000 0.99886234       878\n",
      "           4  0.96612022 0.98550725 0.97571744       897\n",
      "           5  1.00000000 0.99885584 0.99942759       874\n",
      "           6  0.99100112 0.99773499 0.99435666       883\n",
      "           7  0.98400000 0.95879733 0.97123519       898\n",
      "           8  1.00000000 0.99762752 0.99881235       843\n",
      "\n",
      "    accuracy                      0.99218750      7040\n",
      "   macro avg  0.99235608 0.99231537 0.99230145      7040\n",
      "weighted avg  0.99223017 0.99218750 0.99217391      7040\n",
      "\n",
      "==========================================================================================================\n",
      "[{'n_neighbors': 3}, {'max_iter': 10000, 'solver': 'newton-cg'}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_leaf': 1}, {'criterion': 'entropy', 'max_depth': 25, 'n_estimators': 100}, {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train=pd.read_excel('cTTD_features_with_Labels/S2/trainset_60.xls')  #reading the xls file into dataframe\n",
    "    validate=pd.read_excel('cTTD_features_with_Labels/S2/validate_20.xls')\n",
    "    test=pd.read_excel('cTTD_features_with_Labels/S2/testset_20.xls')\n",
    "    \n",
    "    x_tr=train.drop(43,axis=1)    #separating the target values\n",
    "    y_tr=train[43]\n",
    "    x_v=validate.drop(43,axis=1)\n",
    "    y_v=validate[43]\n",
    "    x_te=test.drop(43,axis=1)\n",
    "    y_te=test[43]\n",
    "    \n",
    "    x_train=x_tr.to_numpy()        # converting dataframe to numpy array\n",
    "    y_train=y_tr.to_numpy()\n",
    "    x_val=x_v.to_numpy()\n",
    "    y_val=y_v.to_numpy()\n",
    "    x_test=x_te.to_numpy()\n",
    "    y_test=y_te.to_numpy()\n",
    "    \n",
    "    sc=StandardScaler()\n",
    "    x_train=sc.fit_transform(x_train)       #standardizing the features for better traing process\n",
    "    x_val=sc.fit_transform(x_val)\n",
    "    x_test=sc.fit_transform(x_test)\n",
    "    estimator=[]\n",
    "    \n",
    "    x_train=np.concatenate((x_train,x_val))  #Now combining both training and validation data\n",
    "    y_train=np.concatenate((y_train,y_val))  #Now combing the target values of training and validation data\n",
    "    \n",
    "    \n",
    "    estimator.append(model1(x_train,y_train,x_test,y_test))\n",
    "    print(\"==========================================================================================================\")\n",
    "    \n",
    "    estimator.append(model2(x_train,y_train,x_test,y_test))\n",
    "    print(\"==========================================================================================================\")\n",
    "    \n",
    "    \n",
    "    estimator.append(model3(x_train,y_train,x_test,y_test))\n",
    "    print(\"==========================================================================================================\")\n",
    "    \n",
    "    estimator.append(model5(x_train,y_train,x_test,y_test))\n",
    "    print(\"==========================================================================================================\")\n",
    "    \n",
    "    estimator.append(model6(x_train,y_train,x_test,y_test))\n",
    "    print(\"==========================================================================================================\")\n",
    "    \n",
    "    print(estimator)\n",
    "    \n",
    "   \n",
    "    ''' model7(x_train,x_test,Y_train,y_test,estimator)\n",
    "    print(\"===========================================================================================================\")\n",
    "    \n",
    "    model8(x_train,x_test,Y_train,y_test,estimator)\n",
    "    print(\"===========================================================================================================\")\n",
    "    \n",
    "    model9(x_train,x_test,Y_train,y_test,estimator)\n",
    "    print(\"===========================================================================================================\")\n",
    "    \n",
    "    model10(x_train,x_test,Y_train,y_test,estimator)\n",
    "    print(\"===========================================================================================================\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
