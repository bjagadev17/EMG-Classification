{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all the modules/packages required to complete the given task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier,VotingClassifier,AdaBoostClassifier,GradientBoostingClassifier,StackingClassifier,BaggingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import  GaussianProcessClassifier\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,f1_score,classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model-1 performs the Logistic-Regression on the given task and tuning is done using simple loops and the accuracy comes around 98.25 percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1(x_train,y_train,x_test,y_test):\n",
    "    print(\"Model-1 : Logistic Regression \")\n",
    "    param_grid={'solver':['liblinear','newton-cg','sag'],'max_iter':[10000]}\n",
    "    grid = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='accuracy')\n",
    "    grid.fit(x_train,y_train)\n",
    "    y_test_pred=grid.predict(x_test)\n",
    "    acc_test=round(accuracy_score(y_test_pred,y_test),4)*100\n",
    "    print(\"Accuracy of Model 1 on test set : \",acc_test)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Precision of Model 1 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Recall of Model 1 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"F1-score of Model-1 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])\n",
    "    print(\"Confusion Matrix of Model-1 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n",
    "    return grid.best_params_\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the model-2 which performs the KNearest algorithm.In this model-1,the performance of KNN on the given task is improved Firstly,the datasets is provided with all necessary cleaning and converting to numpy array.I have set a range of values for which ,it will tune the value of k on the validation set such that we can know the value of k whichs performs the best on the validation set.Then we used the best value of k for testing purposes and calculate the accuracy of the model,which comes around 96.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2(x_train,y_train,x_test,y_test):\n",
    "    print(\"Model-2 : K-Nearest Neighbors \")\n",
    "    k_range=[3,7,9,13,15,19,23,25]\n",
    "    param_grid=dict(n_neighbors=k_range)\n",
    "    grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "    grid.fit(x_train,y_train)\n",
    "    y_test_pred=grid.predict(x_test)\n",
    "    acc_t=round(accuracy_score(y_test_pred,y_test),4)*100\n",
    "    print(\"Accuracy of Model 2 on test set : \",acc_t)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Precision of Model 2 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Recall of Model 2 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"F1-score of Model-2 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])\n",
    "    print(\"Confusion Matrix of Model-2 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n",
    "    return grid.best_params_\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine Algorithm is performed onn the given model and accuracy obtained was 99.25 percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model3(x_train,y_train,x_test,y_test):\n",
    "    print(\"Model-3 : Support Vector Machine \")\n",
    "    param_grid={'C':[1,10,100,100],'gamma':['auto',0.1,0.01,0.001],'kernel':['rbf','poly']}\n",
    "    grid = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy')\n",
    "    grid.fit(x_train,y_train)\n",
    "    y_test_pred=grid.predict(x_test)\n",
    "    acc_test=round(accuracy_score(y_test_pred,y_test),4)*100\n",
    "    print(\"Accuracy of Model 3 on test set : \",acc_test)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Precision of Model 3 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Recall of Model 3 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"F1-score of Model-3 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])\n",
    "    print(\"Confusion Matrix of Model-3 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n",
    "    return grid.best_params_\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below model implements the DecisionTree Classification.Here we tune its different parameter and try to get the best parameter by performing holdout validation.Then we used the best parameters of the model on test-set and obtain an accuracy around 95 percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model4(x_train,y_train,x_test,y_test):\n",
    "    print(\"Model-4 : Decision Tree \")\n",
    "    param_grid={'criterion':['gini','entropy'],'max_depth':[5,7,9,13,15,23],'min_samples_leaf':[1,2,5]}\n",
    "    grid = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "    grid.fit(x_train,y_train)\n",
    "    y_test_pred=grid.predict(x_test)\n",
    "    acc_test=round(accuracy_score(y_test_pred,y_test),4)*100\n",
    "    print(\"Accuracy of Model 4 on test set : \",acc_test)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Precision of Model 4 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Recall of Model 4 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"F1-score of Model-4 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])\n",
    "    print(\"Confusion Matrix of Model-4 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n",
    "    return grid.best_params_\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given below function perform the Random Forest Classification on the given data.Hypereparameters are tuned according to the validation set and we test the best parameter on test data so that we can get an accuracy of nearly 98.3 percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model5(x_train,y_train,x_test,y_test):\n",
    "    print(\"Model-5 : Random Forest Classification  \")\n",
    "    param_grid={'n_estimators':[10,50,100,200],'criterion':['gini','entropy'],'max_depth':[5,6,8,13,15,23,25]}\n",
    "    grid = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "    grid.fit(x_train,y_train)\n",
    "    y_test_pred=grid.predict(x_test)\n",
    "    acc_test=round(accuracy_score(y_test_pred,y_test),4)*100\n",
    "    print(\"Accuracy of Model 5 on test set : \",acc_test)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Precision of Model 5 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Recall of Model 5 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"F1-score of Model-5 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])\n",
    "    print(\"Confusion Matrix of Model-5 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n",
    "    return grid.best_params_\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given below function perform the ExtraTrees Classification on the given data.Hypereparameters are tuned according to the validation set and we test the best parameter on test data so that we can get an accuracy more than 98.3 percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model6(x_train,y_train,x_test,y_test):\n",
    "    print(\"Model-6 : ExtraTrees Classification  \")\n",
    "    param_grid={'n_estimators':[10,50,100,200],'criterion':['gini','entropy'],'max_depth':[5,6,8,13,15,23,25]}\n",
    "    grid = GridSearchCV(ExtraTreesClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "    grid.fit(x_train,y_train)\n",
    "    y_test_pred=grid.predict(x_test)\n",
    "    acc_test=round(accuracy_score(y_test_pred,y_test),4)*100\n",
    "    print(\"Accuracy of Model 6 on test set : \",acc_test)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Precision of Model 6 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Recall of Model 6 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"F1-score of Model-6 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])\n",
    "    print(\"Confusion Matrix of Model-6 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n",
    "    return grid.best_params_\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given below is the VotingClassifier which trains on an ensemble of numerous models and predicts an output (class) based on their highest probability of chosen class as the output. It simply aggregates the findings of each classifier passed into Voting Classifier and predicts the output class based on the highest majority of voting. In this hard voting method was used to train the model,the predicted output class was class with highest majority of votes. The accuracy obtained was slightly less than the accuracy obtained from SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model7(x_train,x_test,y_train,y_test,estimator):\n",
    "    e=[('lr',LogisticRegression(solver=estimator[0]['solver'])),\n",
    "       ('knn',KNeighborsClassifier(n_neighbors=estimator[1]['n_neighbors'])),\n",
    "      ('svm',SVC(C=estimator[2]['C'],gamma=estimator[2]['gamma'],kernel='rbf')),\n",
    "      ('dt',DecisionTreeClassifier(criterion=estimator[3]['criterion'],max_depth=estimator[3]['max_depth'])),\n",
    "      ('rf',RandomForestClassifier(n_estimators=estimator[4]['n_estimators'],criterion=estimator[4]['criterion'],max_depth=estimator[4]['max_depth'])),\n",
    "      ('et',ExtraTreesClassifier(n_estimators=estimator[5]['n_estimators'],criterion=estimator[5]['criterion'],max_depth=estimator[5]['max_depth']))]\n",
    "    print(\"Model-7 : VotingClassifier\")\n",
    "    vot_hard=VotingClassifier(estimators = e, voting ='hard') \n",
    "    vot_hard.fit(x_train, y_train)\n",
    "    y_test_pred=vot_hard.predict(x_test)\n",
    "    acc_t=round(accuracy_score(y_test_pred,y_test),4)*100    #accuracy of the predicting model\n",
    "    print(\"Accuracy of Model 7 on test set : \",acc_t)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100   #precision of the predicting model\n",
    "    print(\"Precision of Model 7 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100      #recall_Score of the model\n",
    "    print(\"Recall of Model 7 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100      #f1_score of the model\n",
    "    print(\"F1-score of Model-7 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])   #confusion matrix of the model\n",
    "    print(\"Confusion Matrix of Model-7 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Bagging classifier is an ensemble meta-estimator that fits base classifiers each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. Such a meta-estimator can typically be used as a way to reduce the variance of a black-box estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it.\n",
    "\n",
    "The accuracy obtained was greater than 98.98 percent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model8(x_train,x_test,y_train,y_test,estimator):\n",
    "    print(\"Model-8 : BaggingClassifier\")\n",
    "    bag=BaggingClassifier(base_estimator=SVC(C=estimator[2]['C'],gamma=estimator[2]['gamma'],kernel='rbf'),n_estimators=200,random_state=5) \n",
    "    bag.fit(x_train, y_train)\n",
    "    y_test_pred=bag.predict(x_test)\n",
    "    acc_t=round(accuracy_score(y_test_pred,y_test),4)*100    #accuracy of the predicting model\n",
    "    print(\"Accuracy of Model 8 on test set : \",acc_t)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100   #precision of the predicting model\n",
    "    print(\"Precision of Model 8 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100      #recall_Score of the model\n",
    "    print(\"Recall of Model 8 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100      #f1_score of the model\n",
    "    print(\"F1-score of Model-8 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])   #confusion matrix of the model\n",
    "    print(\"Confusion Matrix of Model-8 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the boosting method in which I have used GradientBoosting and obtain an accuracy around 98.5 percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model9(x_train,x_test,y_train,y_test,estimator):\n",
    "    print(\"Model-9 Gradient-Boosting \")\n",
    "    gbc=GradientBoostingClassifier(n_estimators=200,learning_rate=0.1,subsample=1,random_state=0)\n",
    "    gbc.fit(x_train,y_train)\n",
    "    y_test_pred=gbc.predict(x_test)\n",
    "    acc_t=round(accuracy_score(y_test_pred,y_test),4)*100    #accuracy of the predicting model\n",
    "    print(\"Accuracy of Model 9 on test set : \",acc_t)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100   #precision of the predicting model\n",
    "    print(\"Precision of Model 9 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100      #recall_Score of the model\n",
    "    print(\"Recall of Model 9 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100      #f1_score of the model\n",
    "    print(\"F1-score of Model-9 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])   #confusion matrix of the model\n",
    "    print(\"Confusion Matrix of Model-9 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the implementation of StackingClassifier.Here,we stacked the results obtain from different classifier and stacked together and passed to a final classifier which is SVM and the result obtained was around 99.3 percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model10(x_train,x_test,y_train,y_test,estimator):\n",
    "    esti=[('lr',LogisticRegression(solver=estimator[0]['solver'])),\n",
    "          ('knn',KNeighborsClassifier(n_neighbors=estimator[1]['n_neighbors'])),\n",
    "          ('svm',SVC(C=estimator[2]['C'],gamma=estimator[2]['gamma'],kernel='rbf')),\n",
    "          ('dt',DecisionTreeClassifier(criterion=estimator[3]['criterion'],max_depth=estimator[3]['max_depth'])),\n",
    "          ('rf',RandomForestClassifier(n_estimators=estimator[4]['n_estimators'],criterion=estimator[4]['criterion'],max_depth=estimator[4]['max_depth'])),\n",
    "          ('et',ExtraTreesClassifier(n_estimators=estimator[5]['n_estimators'],criterion=estimator[5]['criterion'],max_depth=estimator[5]['max_depth']))]\n",
    "    print(\"Model-10 : Stacking Classifier \")\n",
    "    stc=StackingClassifier(estimators=esti,final_estimator=SVC(C=estimator[2]['C'],gamma=estimator[2]['gamma'],kernel='rbf'),cv=3)\n",
    "    stc.fit(x_train,y_train)\n",
    "    y_test_pred=stc.predict(x_test)\n",
    "    acc_t=round(accuracy_score(y_test_pred,y_test),4)*100    #accuracy of the predicting model\n",
    "    print(\"Accuracy of Model 10 on test set : \",acc_t)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100   #precision of the predicting model\n",
    "    print(\"Precision of Model 10 on test set : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100      #recall_Score of the model\n",
    "    print(\"Recall of Model 10 on test set : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100      #f1_score of the model\n",
    "    print(\"F1-score of Model-10 on test set : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])   #confusion matrix of the model\n",
    "    print(\"Confusion Matrix of Model-10 on test set : \")\n",
    "    print(con_mat)\n",
    "    print(classification_report(y_test,y_test_pred,digits=8))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model-1 : Logistic Regression \n",
      "Accuracy of Model 1 on test set :  94.64\n",
      "Precision of Model 1 on test set :  94.66\n",
      "Recall of Model 1 on test set :  94.73\n",
      "F1-score of Model-1 on test set :  94.67999999999999\n",
      "Confusion Matrix of Model-1 on test set : \n",
      "[[877   0   0   2   0   0   0   0]\n",
      " [  0 887   1   0   0   0   0   0]\n",
      " [  1   0 863   5   0   9   0   0]\n",
      " [  0   0   7 820   0   7  23  40]\n",
      " [  0   0   0   0 874   0   0   0]\n",
      " [  0   0   3   1   0 805  66   8]\n",
      " [  0   0   0   5   0  85 770  38]\n",
      " [  1   0   0   9   0   9  57 767]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  0.99772469 0.99772469 0.99772469       879\n",
      "           2  1.00000000 0.99887387 0.99943662       888\n",
      "           3  0.98741419 0.98291572 0.98515982       878\n",
      "           4  0.97387173 0.91415831 0.94307073       897\n",
      "           5  1.00000000 1.00000000 1.00000000       874\n",
      "           6  0.87978142 0.91166478 0.89543938       883\n",
      "           7  0.84061135 0.85746102 0.84895259       898\n",
      "           8  0.89917937 0.90984579 0.90448113       843\n",
      "\n",
      "    accuracy                      0.94644886      7040\n",
      "   macro avg  0.94732284 0.94658052 0.94678312      7040\n",
      "weighted avg  0.94733477 0.94644886 0.94672081      7040\n",
      "\n",
      "==========================================================================================================\n",
      "Model-2 : K-Nearest Neighbors \n",
      "Accuracy of Model 2 on test set :  96.78999999999999\n",
      "Precision of Model 2 on test set :  96.8\n",
      "Recall of Model 2 on test set :  96.78\n",
      "F1-score of Model-2 on test set :  96.76\n",
      "Confusion Matrix of Model-2 on test set : \n",
      "[[873   0   5   1   0   0   0   0]\n",
      " [  0 886   0   0   2   0   0   0]\n",
      " [  0   0 873   1   0   4   0   0]\n",
      " [  0   0   0 887   1   0   6   3]\n",
      " [  0   0   0   0 874   0   0   0]\n",
      " [  0   0   1   1   1 844  21  15]\n",
      " [  0   0   0  20   0  47 777  54]\n",
      " [  0   0   0  12   0   5  26 800]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  1.00000000 0.99317406 0.99657534       879\n",
      "           2  1.00000000 0.99774775 0.99887260       888\n",
      "           3  0.99317406 0.99430524 0.99373933       878\n",
      "           4  0.96203905 0.98885173 0.97526113       897\n",
      "           5  0.99544419 1.00000000 0.99771689       874\n",
      "           6  0.93777778 0.95583239 0.94671901       883\n",
      "           7  0.93614458 0.86525612 0.89930556       898\n",
      "           8  0.91743119 0.94899170 0.93294461       843\n",
      "\n",
      "    accuracy                      0.96789773      7040\n",
      "   macro avg  0.96775136 0.96801987 0.96764181      7040\n",
      "weighted avg  0.96790968 0.96789773 0.96765726      7040\n",
      "\n",
      "==========================================================================================================\n",
      "Model-3 : Support Vector Machine \n",
      "Accuracy of Model 3 on test set :  98.2\n",
      "Precision of Model 3 on test set :  98.19\n",
      "Recall of Model 3 on test set :  98.2\n",
      "F1-score of Model-3 on test set :  98.2\n",
      "Confusion Matrix of Model-3 on test set : \n",
      "[[879   0   0   0   0   0   0   0]\n",
      " [  0 888   0   0   0   0   0   0]\n",
      " [  0   0 877   0   0   1   0   0]\n",
      " [  0   0   0 887   0   0   3   7]\n",
      " [  0   0   0   0 874   0   0   0]\n",
      " [  0   0   1   0   0 849  25   8]\n",
      " [  0   0   0   3   0  34 848  13]\n",
      " [  0   0   0   7   0   7  18 811]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  1.00000000 1.00000000 1.00000000       879\n",
      "           2  1.00000000 1.00000000 1.00000000       888\n",
      "           3  0.99886105 0.99886105 0.99886105       878\n",
      "           4  0.98885173 0.98885173 0.98885173       897\n",
      "           5  1.00000000 1.00000000 1.00000000       874\n",
      "           6  0.95286195 0.96149490 0.95715896       883\n",
      "           7  0.94854586 0.94432071 0.94642857       898\n",
      "           8  0.96662694 0.96204033 0.96432818       843\n",
      "\n",
      "    accuracy                      0.98196023      7040\n",
      "   macro avg  0.98196844 0.98194609 0.98195356      7040\n",
      "weighted avg  0.98196560 0.98196023 0.98195922      7040\n",
      "\n",
      "==========================================================================================================\n",
      "Model-4 : Decision Tree \n",
      "Accuracy of Model 4 on test set :  94.16\n",
      "Precision of Model 4 on test set :  94.17999999999999\n",
      "Recall of Model 4 on test set :  94.13\n",
      "F1-score of Model-4 on test set :  94.14\n",
      "Confusion Matrix of Model-4 on test set : \n",
      "[[867   0   8   3   0   0   1   0]\n",
      " [  0 883   3   0   2   0   0   0]\n",
      " [ 15   2 847   7   0   6   0   1]\n",
      " [  5   0   8 835   2   3  23  21]\n",
      " [  4   3   3   0 863   0   1   0]\n",
      " [  0   1   3   7   1 827  31  13]\n",
      " [  7   0   4  29   5  72 738  43]\n",
      " [  0   0   0  18   0  10  46 769]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  0.96547884 0.98634812 0.97580191       879\n",
      "           2  0.99325084 0.99436937 0.99380979       888\n",
      "           3  0.96689498 0.96469248 0.96579247       878\n",
      "           4  0.92880979 0.93088071 0.92984410       897\n",
      "           5  0.98854525 0.98741419 0.98797939       874\n",
      "           6  0.90087146 0.93657984 0.91837868       883\n",
      "           7  0.87857143 0.82182628 0.84925201       898\n",
      "           8  0.90791027 0.91221827 0.91005917       843\n",
      "\n",
      "    accuracy                      0.94161932      7040\n",
      "   macro avg  0.94129161 0.94179116 0.94136469      7040\n",
      "weighted avg  0.94126738 0.94161932 0.94126413      7040\n",
      "\n",
      "==========================================================================================================\n",
      "Model-5 : Random Forest Classification  \n",
      "Accuracy of Model 5 on test set :  97.17\n",
      "Precision of Model 5 on test set :  97.16\n",
      "Recall of Model 5 on test set :  97.2\n",
      "F1-score of Model-5 on test set :  97.17\n",
      "Confusion Matrix of Model-5 on test set : \n",
      "[[875   0   2   0   0   0   2   0]\n",
      " [  0 887   0   0   1   0   0   0]\n",
      " [  1   0 871   0   0   6   0   0]\n",
      " [  0   0   0 876   0   2  11   8]\n",
      " [  0   0   0   0 874   0   0   0]\n",
      " [  0   0   1   0   0 858  14  10]\n",
      " [  2   0   0   5   0  45 824  22]\n",
      " [  0   0   0   1   0   8  58 776]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  0.99658314 0.99544937 0.99601594       879\n",
      "           2  1.00000000 0.99887387 0.99943662       888\n",
      "           3  0.99656751 0.99202733 0.99429224       878\n",
      "           4  0.99319728 0.97658863 0.98482293       897\n",
      "           5  0.99885714 1.00000000 0.99942824       874\n",
      "           6  0.93362350 0.97168743 0.95227525       883\n",
      "           7  0.90649065 0.91759465 0.91200885       898\n",
      "           8  0.95098039 0.92052195 0.93550332       843\n",
      "\n",
      "    accuracy                      0.97173295      7040\n",
      "   macro avg  0.97203745 0.97159291 0.97172292      7040\n",
      "weighted avg  0.97201372 0.97173295 0.97178197      7040\n",
      "\n",
      "==========================================================================================================\n",
      "Model-6 : ExtraTrees Classification  \n",
      "Accuracy of Model 6 on test set :  97.43\n",
      "Precision of Model 6 on test set :  97.42\n",
      "Recall of Model 6 on test set :  97.42\n",
      "F1-score of Model-6 on test set :  97.42\n",
      "Confusion Matrix of Model-6 on test set : \n",
      "[[878   0   0   0   0   0   1   0]\n",
      " [  0 887   0   0   1   0   0   0]\n",
      " [  0   0 876   0   0   2   0   0]\n",
      " [  0   0   0 888   0   0   6   3]\n",
      " [  0   0   0   0 874   0   0   0]\n",
      " [  0   0   0   0   0 852  17  14]\n",
      " [  0   0   0   7   0  44 815  32]\n",
      " [  0   0   0   2   0   6  46 789]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  1.00000000 0.99886234 0.99943085       879\n",
      "           2  1.00000000 0.99887387 0.99943662       888\n",
      "           3  1.00000000 0.99772210 0.99885975       878\n",
      "           4  0.98996656 0.98996656 0.98996656       897\n",
      "           5  0.99885714 1.00000000 0.99942824       874\n",
      "           6  0.94247788 0.96489241 0.95355344       883\n",
      "           7  0.92090395 0.90757238 0.91418957       898\n",
      "           8  0.94152745 0.93594306 0.93872695       843\n",
      "\n",
      "    accuracy                      0.97428977      7040\n",
      "   macro avg  0.97421662 0.97422909 0.97419900      7040\n",
      "weighted avg  0.97427393 0.97428977 0.97425786      7040\n",
      "\n",
      "==========================================================================================================\n",
      "[{'max_iter': 10000, 'solver': 'newton-cg'}, {'n_neighbors': 7}, {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}, {'criterion': 'entropy', 'max_depth': 15, 'min_samples_leaf': 5}, {'criterion': 'entropy', 'max_depth': 25, 'n_estimators': 100}, {'criterion': 'entropy', 'max_depth': 23, 'n_estimators': 200}]\n",
      "Model-7 : VotingClassifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model 7 on test set :  97.76\n",
      "Precision of Model 7 on test set :  97.75\n",
      "Recall of Model 7 on test set :  97.76\n",
      "F1-score of Model-7 on test set :  97.75\n",
      "Confusion Matrix of Model-7 on test set : \n",
      "[[879   0   0   0   0   0   0   0]\n",
      " [  0 888   0   0   0   0   0   0]\n",
      " [  1   0 876   0   0   1   0   0]\n",
      " [  0   0   1 888   0   0   5   3]\n",
      " [  0   0   0   0 874   0   0   0]\n",
      " [  0   0   0   0   0 862  12   9]\n",
      " [  0   0   0   4   0  51 824  19]\n",
      " [  0   0   0   6   0   3  43 791]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  0.99886364 1.00000000 0.99943150       879\n",
      "           2  1.00000000 1.00000000 1.00000000       888\n",
      "           3  0.99885975 0.99772210 0.99829060       878\n",
      "           4  0.98886414 0.98996656 0.98941504       897\n",
      "           5  1.00000000 1.00000000 1.00000000       874\n",
      "           6  0.94002181 0.97621744 0.95777778       883\n",
      "           7  0.93212670 0.91759465 0.92480359       898\n",
      "           8  0.96228710 0.93831554 0.95015015       843\n",
      "\n",
      "    accuracy                      0.97755682      7040\n",
      "   macro avg  0.97762789 0.97747704 0.97748358      7040\n",
      "weighted avg  0.97760060 0.97755682 0.97751033      7040\n",
      "\n",
      "===========================================================================================================\n",
      "Model-8 : BaggingClassifier\n",
      "Accuracy of Model 8 on test set :  98.18\n",
      "Precision of Model 8 on test set :  98.18\n",
      "Recall of Model 8 on test set :  98.18\n",
      "F1-score of Model-8 on test set :  98.18\n",
      "Confusion Matrix of Model-8 on test set : \n",
      "[[879   0   0   0   0   0   0   0]\n",
      " [  0 888   0   0   0   0   0   0]\n",
      " [  0   0 877   0   0   1   0   0]\n",
      " [  0   0   0 883   0   1   4   9]\n",
      " [  0   0   0   0 874   0   0   0]\n",
      " [  0   0   1   0   0 849  25   8]\n",
      " [  0   0   0   3   0  33 850  12]\n",
      " [  0   0   0   7   0   6  18 812]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  1.00000000 1.00000000 1.00000000       879\n",
      "           2  1.00000000 1.00000000 1.00000000       888\n",
      "           3  0.99886105 0.99886105 0.99886105       878\n",
      "           4  0.98880179 0.98439242 0.98659218       897\n",
      "           5  1.00000000 1.00000000 1.00000000       874\n",
      "           6  0.95393258 0.96149490 0.95769882       883\n",
      "           7  0.94760312 0.94654788 0.94707521       898\n",
      "           8  0.96551724 0.96322657 0.96437055       843\n",
      "\n",
      "    accuracy                      0.98181818      7040\n",
      "   macro avg  0.98183947 0.98181535 0.98182472      7040\n",
      "weighted avg  0.98184039 0.98181818 0.98182658      7040\n",
      "\n",
      "===========================================================================================================\n",
      "Model-9 Gradient-Boosting \n",
      "Accuracy of Model 9 on test set :  97.24000000000001\n",
      "Precision of Model 9 on test set :  97.24000000000001\n",
      "Recall of Model 9 on test set :  97.27\n",
      "F1-score of Model-9 on test set :  97.25\n",
      "Confusion Matrix of Model-9 on test set : \n",
      "[[875   0   3   0   0   0   1   0]\n",
      " [  0 887   0   0   1   0   0   0]\n",
      " [  0   0 871   1   0   5   1   0]\n",
      " [  1   0   2 876   0   1  10   7]\n",
      " [  0   0   0   0 873   0   1   0]\n",
      " [  0   0   1   1   0 855  18   8]\n",
      " [  1   0   0   9   0  52 818  18]\n",
      " [  0   0   0   2   0   6  44 791]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  0.99771950 0.99544937 0.99658314       879\n",
      "           2  1.00000000 0.99887387 0.99943662       888\n",
      "           3  0.99315849 0.99202733 0.99259259       878\n",
      "           4  0.98537683 0.97658863 0.98096305       897\n",
      "           5  0.99885584 0.99885584 0.99885584       874\n",
      "           6  0.93035909 0.96828992 0.94894562       883\n",
      "           7  0.91601344 0.91091314 0.91345617       898\n",
      "           8  0.95995146 0.93831554 0.94901020       843\n",
      "\n",
      "    accuracy                      0.97244318      7040\n",
      "   macro avg  0.97267933 0.97241421 0.97248040      7040\n",
      "weighted avg  0.97261333 0.97244318 0.97246231      7040\n",
      "\n",
      "===========================================================================================================\n",
      "Model-10 : Stacking Classifier \n",
      "Accuracy of Model 10 on test set :  97.64\n",
      "Precision of Model 10 on test set :  97.63\n",
      "Recall of Model 10 on test set :  97.67\n",
      "F1-score of Model-10 on test set :  97.64\n",
      "Confusion Matrix of Model-10 on test set : \n",
      "[[876   0   3   0   0   0   0   0]\n",
      " [  0 888   0   0   0   0   0   0]\n",
      " [  1   0 858   0   0  19   0   0]\n",
      " [  0   0   0 893   0   0   3   1]\n",
      " [  0   0   0   0 874   0   0   0]\n",
      " [  0   0   1   0   0 851  21  10]\n",
      " [  0   0   0   2   0  37 845  14]\n",
      " [  0   0   0  27   0   9  18 789]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  0.99885975 0.99658703 0.99772210       879\n",
      "           2  1.00000000 1.00000000 1.00000000       888\n",
      "           3  0.99535963 0.97722096 0.98620690       878\n",
      "           4  0.96854664 0.99554069 0.98185816       897\n",
      "           5  1.00000000 1.00000000 1.00000000       874\n",
      "           6  0.92903930 0.96375991 0.94608116       883\n",
      "           7  0.95264938 0.94097996 0.94677871       898\n",
      "           8  0.96928747 0.93594306 0.95232348       843\n",
      "\n",
      "    accuracy                      0.97642045      7040\n",
      "   macro avg  0.97671777 0.97625395 0.97637131      7040\n",
      "weighted avg  0.97665341 0.97642045 0.97642326      7040\n",
      "\n",
      "===========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train=pd.read_excel('cTTD_features_with_Labels/S5/trainset_60.xls')  #reading the xls file into dataframe\n",
    "    validate=pd.read_excel('cTTD_features_with_Labels/S5/validate_20.xls')\n",
    "    test=pd.read_excel('cTTD_features_with_Labels/S5/testset_20.xls')\n",
    "    \n",
    "    x_tr=train.drop(43,axis=1)    #separating the target values\n",
    "    y_tr=train[43]\n",
    "    x_v=validate.drop(43,axis=1)\n",
    "    y_v=validate[43]\n",
    "    x_te=test.drop(43,axis=1)\n",
    "    y_te=test[43]\n",
    "    \n",
    "    x_train=x_tr.to_numpy()        # converting dataframe to numpy array\n",
    "    y_train=y_tr.to_numpy()\n",
    "    x_val=x_v.to_numpy()\n",
    "    y_val=y_v.to_numpy()\n",
    "    x_test=x_te.to_numpy()\n",
    "    y_test=y_te.to_numpy()\n",
    "    \n",
    "    sc=StandardScaler()\n",
    "    x_train=sc.fit_transform(x_train)       #standardizing the features for better traing process\n",
    "    x_val=sc.fit_transform(x_val)\n",
    "    x_test=sc.fit_transform(x_test)\n",
    "    estimator=[]\n",
    "    \n",
    "    x_train=np.concatenate((x_train,x_val))  #Now combining both training and validation data\n",
    "    y_train=np.concatenate((y_train,y_val))  #Now combing the target values of training and validation data\n",
    "    \n",
    "    \n",
    "    estimator.append(model1(x_train,y_train,x_test,y_test))\n",
    "    print(\"==========================================================================================================\")\n",
    "    \n",
    "    estimator.append(model2(x_train,y_train,x_test,y_test))\n",
    "    print(\"==========================================================================================================\")\n",
    "    \n",
    "    \n",
    "    estimator.append(model3(x_train,y_train,x_test,y_test))\n",
    "    print(\"==========================================================================================================\")\n",
    "    \n",
    "    estimator.append(model4(x_train,y_train,x_test,y_test))\n",
    "    print(\"==========================================================================================================\")\n",
    "    \n",
    "    \n",
    "    estimator.append(model5(x_train,y_train,x_test,y_test))\n",
    "    print(\"==========================================================================================================\")\n",
    "    \n",
    "    estimator.append(model6(x_train,y_train,x_test,y_test))\n",
    "    print(\"==========================================================================================================\")\n",
    "    \n",
    "    print(estimator)\n",
    "    \n",
    "   \n",
    "    model7(x_train,x_test,y_train,y_test,estimator)\n",
    "    print(\"===========================================================================================================\")\n",
    "    \n",
    "    model8(x_train,x_test,y_train,y_test,estimator)\n",
    "    print(\"===========================================================================================================\")\n",
    "    \n",
    "    model9(x_train,x_test,y_train,y_test,estimator)\n",
    "    print(\"===========================================================================================================\")\n",
    "    \n",
    "    model10(x_train,x_test,y_train,y_test,estimator)\n",
    "    print(\"===========================================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
