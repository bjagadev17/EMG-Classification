{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,f1_score,roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2(x_train,y_train,x_val,y_val,x_test,y_test):\n",
    "    lr=LogisticRegression(max_iter=1000)  #again training the model with best hyperparameter\n",
    "    lr.fit(x_train,y_train)\n",
    "    y_test_pred=lr.predict(x_test)   #fitting the training data into model\n",
    "    print(\"Model-2 : Logistic Regression\")  \n",
    "    acc_t=round(accuracy_score(y_test_pred,y_test),4)*100 #accuracy of the model\n",
    "    print(\"Accuracy of Model 2 on test set before tuning : \",acc_t)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100   #precision score\n",
    "    print(\"Precision of Model 2 on test set before tuning : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Recall of Model 2 on test set before tuning: \",rec)      #recall_score\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"F1-score of Model-2 on test set before tuning : \",f_score)    #f1_Score\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8]) #confusion matrix\n",
    "    print(\"Confusion Matrix of Model-2 on test set before tuning: \")\n",
    "    print(con_mat)\n",
    "    print(\"-------------------------------------------------------------------------------------------------\")\n",
    "    print(\"Tuning the hyperparameter with the help of validation set\")\n",
    "    solver=['saga','liblinear']             #taking a list which contains different algorithm that can be used to optimize \n",
    "    multi_class=['auto','ovr']              #list containing different multi_class parameter\n",
    "    c=[10,100]                              #list containing different inverse regularization values\n",
    "    feature=[]\n",
    "    a=[]\n",
    "    for i in solver:\n",
    "        for j in multi_class:\n",
    "            for k in c:\n",
    "                lr=LogisticRegression(solver=i,max_iter=10000,multi_class=j,penalty='l1',C=k)   #tuning the model each time with a new hyperparameter\n",
    "                lr.fit(x_train,y_train)\n",
    "                y_val_pred=lr.predict(x_val)\n",
    "                acc=round(accuracy_score(y_val_pred,y_val),4)*100\n",
    "                feature.append((i,j,k))\n",
    "                a.append(acc)\n",
    "    m=max(a)       #getting the maximum accuracy from validation set\n",
    "    p=a.index(m)   #getting the index of the max_accuracy\n",
    "    lr=LogisticRegression(solver=feature[p][0],multi_class=feature[p][1],max_iter=10000,penalty='l1',C=feature[p][2])  #again training the model with best hyperparameter\n",
    "    x_train=np.concatenate((x_train,x_val))  #Now combining both training and validation data\n",
    "    y_train=np.concatenate((y_train,y_val))  #Now combing the target values of training and validation data\n",
    "    lr.fit(x_train,y_train)\n",
    "    y_test_pred=lr.predict(x_test)   #fitting the training data into model  \n",
    "    acc_t=round(accuracy_score(y_test_pred,y_test),4)*100 #accuracy of the model\n",
    "    print(\"Accuracy of Model 2 on test set after tuning: \",acc_t)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100   #precision score\n",
    "    print(\"Precision of Model 2 on test set after tuning: \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"Recall of Model 2 on test set after tuning: \",rec)      #recall_score\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100\n",
    "    print(\"F1-score of Model-2 on test set after tuning: \",f_score)    #f1_Score\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8]) #confusion matrix\n",
    "    print(\"Confusion Matrix of Model-2 on test set after tuning: \")\n",
    "    print(con_mat)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model-2 : Logistic Regression\n",
      "Accuracy of Model 2 on test set before tuning :  92.4\n",
      "Precision of Model 2 on test set before tuning :  92.47\n",
      "Recall of Model 2 on test set before tuning:  92.44\n",
      "F1-score of Model-2 on test set before tuning :  92.44\n",
      "Confusion Matrix of Model-2 on test set before tuning: \n",
      "[[870   0   7   0   2   0   0   0]\n",
      " [  0 880   0   1   0   6   1   0]\n",
      " [  2   0 849  16   7   3   0   1]\n",
      " [  0   2  23 723   7  16 109  17]\n",
      " [  0   3   8   4 814  41   4   0]\n",
      " [  0  21  10  20  23 775  34   0]\n",
      " [  0   0   0  70  13  47 768   0]\n",
      " [  0   0   1  15   0   1   0 826]]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Tuning the hyperparameter with the help of validation set\n",
      "Accuracy of Model 2 on test set after tuning:  97.56\n",
      "Precision of Model 2 on test set after tuning:  97.59\n",
      "Recall of Model 2 on test set after tuning:  97.58\n",
      "F1-score of Model-2 on test set after tuning:  97.58\n",
      "Confusion Matrix of Model-2 on test set after tuning: \n",
      "[[878   0   1   0   0   0   0   0]\n",
      " [  0 887   0   0   0   1   0   0]\n",
      " [  0   0 869   2   2   3   0   2]\n",
      " [  0   3   5 843   1   4  37   4]\n",
      " [  0   0   2   0 864   8   0   0]\n",
      " [  0   4   5   3   1 859  11   0]\n",
      " [  0   0   0  49   1  17 831   0]\n",
      " [  0   0   1   3   0   1   1 837]]\n",
      "==========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train=pd.read_excel('cTTD_features_with_Labels/S2/trainset_60.xls')  #reading the xls file into dataframe\n",
    "    validate=pd.read_excel('cTTD_features_with_Labels/S2/validate_20.xls')\n",
    "    test=pd.read_excel('cTTD_features_with_Labels/S2/testset_20.xls')\n",
    "    \n",
    "    x_tr=train.drop(43,axis=1)    #separating the target values\n",
    "    y_tr=train[43]\n",
    "    x_v=validate.drop(43,axis=1)\n",
    "    y_v=validate[43]\n",
    "    x_te=test.drop(43,axis=1)\n",
    "    y_te=test[43]\n",
    "    \n",
    "    x_train=x_tr.to_numpy()        # converting dataframe to numpy array\n",
    "    y_train=y_tr.to_numpy()\n",
    "    x_val=x_v.to_numpy()\n",
    "    y_val=y_v.to_numpy()\n",
    "    x_test=x_te.to_numpy()\n",
    "    y_test=y_te.to_numpy()\n",
    "    \n",
    "    model2(x_train,y_train,x_val,y_val,x_test,y_test)\n",
    "    print(\"==========================================================================================================\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the total analysis done using Logistic Regression.The model is properly tuned with the help of validation set.Several parameters were tuned to increase the model effciency.As it can be seen that accuracy before tuning the parameter was 92.44 percent and after tuning it jumps to 97.56 percent.The precision of the model also raise to 97.59 percent after tuning the model.The recall also rose to 97.58 after tuning the hyperparameter.F1 score before tuning was 92.44 whereas after tuning it became 97.58 percent.As there is not much difference between precision and recall,accuracy will be ideal metric choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary\n",
    " 1. This is the total analysis done using Logistic Regression.\n",
    " 2. First ,datasets was converted into numpy array so that it can be easily put in the model.\n",
    " 3. Then we normally train the model without tuning any of its hyperparameter and then test it on test dataset and observe the       metrics \n",
    " 4. After that we tuned the hyperparameters by varying with different values and checked it on validation set and after gettig       the best hyperparameters and after that we combine both train and validate and train as a whole.\n",
    " 5. After that we checked the accuracy,precision,recall,confusion-matrix as well as F1 score of the testing data with predicted     value\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
