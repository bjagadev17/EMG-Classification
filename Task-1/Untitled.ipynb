{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier,VotingClassifier,AdaBoostClassifier,GradientBoostingClassifier,StackingClassifier,BaggingClassifier\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,f1_score,classification_report\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_excel('cTTD_features_with_Labels/S2/trainset_60.xls')  #reading the xls file into dataframe\n",
    "validate=pd.read_excel('cTTD_features_with_Labels/S2/validate_20.xls')\n",
    "test=pd.read_excel('cTTD_features_with_Labels/S2/testset_20.xls')\n",
    "    \n",
    "x_tr=train.drop(43,axis=1)    #separating the target values\n",
    "y_tr=train[43]\n",
    "x_v=validate.drop(43,axis=1)\n",
    "y_v=validate[43]\n",
    "x_te=test.drop(43,axis=1)\n",
    "y_te=test[43]\n",
    "    \n",
    "x_train=x_tr.to_numpy()        # converting dataframe to numpy array\n",
    "y_train=y_tr.to_numpy()\n",
    "x_val=x_v.to_numpy()\n",
    "y_val=y_v.to_numpy()\n",
    "x_test=x_te.to_numpy()\n",
    "y_test=y_te.to_numpy()\n",
    "    \n",
    "sc=StandardScaler()\n",
    "x_train=sc.fit_transform(x_train)       #standardizing the features for better traing process\n",
    "x_val=sc.fit_transform(x_val)\n",
    "x_test=sc.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.concatenate((x_train,x_val))  #Now combining both training and validation data\n",
    "y_train=np.concatenate((y_train,y_val))  #Now combing the target values of training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator=[('svc',SVC(C=100,kernel='rbf',random_state=0,gamma='auto',class_weight='balanced')),('rf',RandomForestClassifier(n_estimators=200,criterion='entropy',max_depth=23)),\n",
    "          ('lg',LogisticRegression(solver='newton-cg')),('knn',KNeighborsClassifier(n_neighbors=5)),\n",
    "          ('mt',ExtraTreesClassifier(n_estimators=200,criterion='entropy',max_depth=23))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vot_hard=VotingClassifier(estimators = estimator, voting ='hard') \n",
    "vot_hard.fit(x_train, y_train)\n",
    "y_test_pred=vot_hard.predict(x_test)\n",
    "acc_t=round(accuracy_score(y_test_pred,y_test),4)*100    #accuracy of the predicting model\n",
    "print(\"Accuracy of Model 7 on test set : \",acc_t)\n",
    "pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100   #precision of the predicting model\n",
    "print(\"Precision of Model 7 on test set : \",pre)\n",
    "rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100      #recall_Score of the model\n",
    "print(\"Recall of Model 7 on test set : \",rec)\n",
    "f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100      #f1_score of the model\n",
    "print(\"F1-score of Model-7 on test set : \",f_score)\n",
    "con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])   #confusion matrix of the model\n",
    "print(\"Confusion Matrix of Model-7 on test set : \")\n",
    "print(con_mat)\n",
    "print(classification_report(y_test,y_test_pred,digits=8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag=BaggingClassifier(base_estimator=SVC(C=100,gamma='auto'),n_estimators=200,random_state=5) \n",
    "bag.fit(x_train, y_train)\n",
    "y_test_pred=bag.predict(x_test)\n",
    "acc_t=round(accuracy_score(y_test_pred,y_test),4)*100    #accuracy of the predicting model\n",
    "print(\"Accuracy of Model 8 on test set : \",acc_t)\n",
    "pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100   #precision of the predicting model\n",
    "print(\"Precision of Model 8 on test set : \",pre)\n",
    "rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100      #recall_Score of the model\n",
    "print(\"Recall of Model 8 on test set : \",rec)\n",
    "f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100      #f1_score of the model\n",
    "print(\"F1-score of Model-8 on test set : \",f_score)\n",
    "con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])   #confusion matrix of the model\n",
    "print(\"Confusion Matrix of Model-8 on test set : \")\n",
    "print(con_mat)\n",
    "print(classification_report(y_test,y_test_pred,digits=8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada=AdaBoostClassifier(base_estimator=SVC(C=100,gamma='auto',kernel='rbf',random_state=0,class_weight='balanced'),n_estimators=100,learning_rate=0.1,algorithm='SAMME',random_state=4)\n",
    "ada.fit(x_train,y_train)\n",
    "y_test_pred=ada.predict(x_test)\n",
    "acc_t=round(accuracy_score(y_test_pred,y_test),4)*100    #accuracy of the predicting model\n",
    "print(\"Accuracy of Model 8 on test set : \",acc_t)\n",
    "pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100   #precision of the predicting model\n",
    "print(\"Precision of Model 8 on test set : \",pre)\n",
    "rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100      #recall_Score of the model\n",
    "print(\"Recall of Model 8 on test set : \",rec)\n",
    "f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100      #f1_score of the model\n",
    "print(\"F1-score of Model-8 on test set : \",f_score)\n",
    "con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])   #confusion matrix of the model\n",
    "print(\"Confusion Matrix of Model-8 on test set : \")\n",
    "print(con_mat)\n",
    "print(classification_report(y_test,y_test_pred,digits=8))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GradientBoostingClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c2bf69df7e98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgbc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msubsample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mgbc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_test_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgbc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0macc_t\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m    \u001b[1;31m#accuracy of the predicting model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy of Model 8 on test set : \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GradientBoostingClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "gbc=GradientBoostingClassifier(n_estimators=200,learning_rate=0.1,subsample=1,random_state=0)\n",
    "gbc.fit(x_train,y_train)\n",
    "y_test_pred=gbc.predict(x_test)\n",
    "acc_t=round(accuracy_score(y_test_pred,y_test),4)*100    #accuracy of the predicting model\n",
    "print(\"Accuracy of Model 8 on test set : \",acc_t)\n",
    "pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100   #precision of the predicting model\n",
    "print(\"Precision of Model 8 on test set : \",pre)\n",
    "rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100      #recall_Score of the model\n",
    "print(\"Recall of Model 8 on test set : \",rec)\n",
    "f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100      #f1_score of the model\n",
    "print(\"F1-score of Model-8 on test set : \",f_score)\n",
    "con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])   #confusion matrix of the model\n",
    "print(\"Confusion Matrix of Model-8 on test set : \")\n",
    "print(con_mat)\n",
    "print(classification_report(y_test,y_test_pred,digits=8))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stc=StackingClassifier(estimators=estimator,final_estimator=SVC(C=100,kernel='rbf',random_state=0,gamma='auto',class_weight='balanced'),cv=5)\n",
    "stc.fit(x_train,y_train)\n",
    "y_test_pred=stc.predict(x_test)\n",
    "acc_t=round(accuracy_score(y_test_pred,y_test),4)*100    #accuracy of the predicting model\n",
    "print(\"Accuracy of Model 8 on test set : \",acc_t)\n",
    "pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100   #precision of the predicting model\n",
    "print(\"Precision of Model 8 on test set : \",pre)\n",
    "rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100      #recall_Score of the model\n",
    "print(\"Recall of Model 8 on test set : \",rec)\n",
    "f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100      #f1_score of the model\n",
    "print(\"F1-score of Model-8 on test set : \",f_score)\n",
    "con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])   #confusion matrix of the model\n",
    "print(\"Confusion Matrix of Model-8 on test set : \")\n",
    "print(con_mat)\n",
    "print(classification_report(y_test,y_test_pred,digits=8))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model 8 on test set :  99.25\n",
      "Precision of Model 8 on test set :  99.26\n",
      "Recall of Model 8 on test set :  99.26\n",
      "F1-score of Model-8 on test set :  99.26\n",
      "Confusion Matrix of Model-8 on test set : \n",
      "[[879   0   0   0   0   0   0   0]\n",
      " [  0 888   0   0   0   0   0   0]\n",
      " [  0   0 878   0   0   0   0   0]\n",
      " [  0   0   2 885   0   0  10   0]\n",
      " [  0   0   0   0 873   1   0   0]\n",
      " [  0   0   0   0   0 881   2   0]\n",
      " [  0   0   0  30   0   7 861   0]\n",
      " [  0   0   1   0   0   0   0 842]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1  1.00000000 1.00000000 1.00000000       879\n",
      "           2  1.00000000 1.00000000 1.00000000       888\n",
      "           3  0.99659478 1.00000000 0.99829449       878\n",
      "           4  0.96721311 0.98662207 0.97682119       897\n",
      "           5  1.00000000 0.99885584 0.99942759       874\n",
      "           6  0.99100112 0.99773499 0.99435666       883\n",
      "           7  0.98625430 0.95879733 0.97233202       898\n",
      "           8  1.00000000 0.99881376 0.99940653       843\n",
      "\n",
      "    accuracy                      0.99247159      7040\n",
      "   macro avg  0.99263291 0.99260300 0.99257981      7040\n",
      "weighted avg  0.99251573 0.99247159 0.99245478      7040\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc=SVC(C=100,kernel='rbf',gamma='auto')\n",
    "svc.fit(x_train,y_train)\n",
    "y_test_pred=svc.predict(x_test)\n",
    "acc_t=round(accuracy_score(y_test_pred,y_test),4)*100    #accuracy of the predicting model\n",
    "print(\"Accuracy of Model 8 on test set : \",acc_t)\n",
    "pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100   #precision of the predicting model\n",
    "print(\"Precision of Model 8 on test set : \",pre)\n",
    "rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100      #recall_Score of the model\n",
    "print(\"Recall of Model 8 on test set : \",rec)\n",
    "f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100      #f1_score of the model\n",
    "print(\"F1-score of Model-8 on test set : \",f_score)\n",
    "con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])   #confusion matrix of the model\n",
    "print(\"Confusion Matrix of Model-8 on test set : \")\n",
    "print(con_mat)\n",
    "print(classification_report(y_test,y_test_pred,digits=8))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb=XGBClassifier(n_estimators=500)\n",
    "xgb.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred=xgb.predict(x_test)\n",
    "acc_t=round(accuracy_score(y_test_pred,y_test),4)*100    #accuracy of the predicting model\n",
    "print(\"Accuracy of Model 8 on test set : \",acc_t)\n",
    "pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100   #precision of the predicting model\n",
    "print(\"Precision of Model 8 on test set : \",pre)\n",
    "rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100      #recall_Score of the model\n",
    "print(\"Recall of Model 8 on test set : \",rec)\n",
    "f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100      #f1_score of the model\n",
    "print(\"F1-score of Model-8 on test set : \",f_score)\n",
    "con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])   #confusion matrix of the model\n",
    "print(\"Confusion Matrix of Model-8 on test set : \")\n",
    "print(con_mat)\n",
    "print(classification_report(y_test,y_test_pred,digits=8))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.la"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
