{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,f1_score,roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model7(x_train,y_train,x_val,y_val,x_test,y_test):\n",
    "    sgd=SGDClassifier()\n",
    "    sgd.fit(x_train,y_train)        #fitting the training data into the model\n",
    "    y_test_pred=sgd.predict(x_test) #predicting the test data\n",
    "    print(\"Model-7: SGD Method \")\n",
    "    acc_t=round(accuracy_score(y_test_pred,y_test),4)*100         #accuracy of the predicting model\n",
    "    print(\"Accuracy of Model 7 on test set before tuning: \",acc_t)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100    #precision of the predicting model\n",
    "    print(\"Precision of Model 7 on test set before tuning : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100        #recall_Score of the model\n",
    "    print(\"Recall of Model 7 on test set before tuning: \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100        #f1_score of the model\n",
    "    print(\"F1-score of Model-7 on test set before tuning : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])    #confusion matrix of the model\n",
    "    print(\"Confusion Matrix of Model-7 on test set before tuning: \")\n",
    "    print(con_mat)\n",
    "    print(\"------------------------------------------------------------------------------------------------------------------\")\n",
    "    print(\"Tuning the hyperparameters with the help of validation set\")\n",
    "    loss=['squared_hinge','modified_huber','perceptron','log','hinge']       #first hyper-parameter list containing the various method to calculate loss\n",
    "    alpha=[0.00001,0.0001,0.00000001]                                      #second hyper-parameter list containing different alpha\n",
    "    learning_rate=['adaptive','optimal','invscaling']                        #third hyper-parameter is the list containing different learning rate\n",
    "    feature=[]                                                          #list that will contain different combination of hyperparameter\n",
    "    a=[]                                                                #list will contain different accuracy by combining different parameters\n",
    "    for i in loss:\n",
    "        for j in alpha:\n",
    "            for k in learning_rate:\n",
    "                    sgd=SGDClassifier(loss=i,alpha=j,learning_rate=k,eta0=1,max_iter=1000000,penalty='l1')\n",
    "                    sgd.fit(x_train,y_train)\n",
    "                    y_val_pred=sgd.predict(x_val)\n",
    "                    acc=round(accuracy_score(y_val_pred,y_val),4)*100\n",
    "                    feature.append((i,j,k))\n",
    "                    a.append(acc)\n",
    "    m=max(a)                        #getting the maximum accuracy\n",
    "    p=a.index(m)                    #getting the index of max accuracy to obtain the best hyperparameters\n",
    "    sgd=SGDClassifier(loss=feature[p][0],alpha=feature[p][1],learning_rate=feature[p][2],max_iter=1000000,eta0=1,penalty='l1') #declaring the model with best parameter\n",
    "    x_train=np.concatenate((x_train,x_val))  #Now combining both training and validation data\n",
    "    y_train=np.concatenate((y_train,y_val))  #Now combing the target values of training and validation data\n",
    "    sgd.fit(x_train,y_train)        #fitting the training data into the model\n",
    "    y_test_pred=sgd.predict(x_test) #predicting the test data\n",
    "    acc_t=round(accuracy_score(y_test_pred,y_test),4)*100         #accuracy of the predicting model\n",
    "    print(\"Accuracy of Model 7 on test set after tuning : \",acc_t)\n",
    "    pre=round(precision_score(y_test_pred,y_test,average='macro'),4)*100    #precision of the predicting model\n",
    "    print(\"Precision of Model 7 on test set after tuning : \",pre)\n",
    "    rec=round(recall_score(y_test_pred,y_test,average='macro'),4)*100        #recall_Score of the model\n",
    "    print(\"Recall of Model 7 on test set after tuning : \",rec)\n",
    "    f_score=round(f1_score(y_test_pred,y_test,average='macro'),4)*100        #f1_score of the model\n",
    "    print(\"F1-score of Model-7 on test set after tuning : \",f_score)\n",
    "    con_mat=confusion_matrix(y_test,y_test_pred,labels=[1,2,3,4,5,6,7,8])    #confusion matrix of the model\n",
    "    print(\"Confusion Matrix of Model-7 on test set after tuning : \")\n",
    "    print(con_mat)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model-7: SGD Method \n",
      "Accuracy of Model 7 on test set before tuning:  89.52\n",
      "Precision of Model 7 on test set before tuning :  89.64999999999999\n",
      "Recall of Model 7 on test set before tuning:  90.12\n",
      "F1-score of Model-7 on test set before tuning :  89.03999999999999\n",
      "Confusion Matrix of Model-7 on test set before tuning: \n",
      "[[876   0   3   0   0   0   0   0]\n",
      " [  0 888   0   0   0   0   0   0]\n",
      " [  6   1 838   0  16   6   0  11]\n",
      " [  0  25  32 485   6  27 220 102]\n",
      " [  0   6   7   2 826  30   2   1]\n",
      " [  0  51  11   4  40 733  44   0]\n",
      " [  0   1   0  25  15  41 814   2]\n",
      " [  0   0   1   0   0   0   0 842]]\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "Tuning the hyperparameters with the help of validation set\n",
      "Accuracy of Model 7 on test set after tuning :  94.52000000000001\n",
      "Precision of Model 7 on test set after tuning :  94.58\n",
      "Recall of Model 7 on test set after tuning :  94.53\n",
      "F1-score of Model-7 on test set after tuning :  94.54\n",
      "Confusion Matrix of Model-7 on test set after tuning : \n",
      "[[876   0   3   0   0   0   0   0]\n",
      " [  0 884   0   0   0   4   0   0]\n",
      " [  1   0 853  11   6   2   1   4]\n",
      " [  0   1  14 793   1  14  61  13]\n",
      " [  0   0   2   0 860  10   2   0]\n",
      " [  0  12  18   6  26 790  31   0]\n",
      " [  1   0   0  89   4  36 768   0]\n",
      " [  0   0   4   8   0   0   1 830]]\n",
      "==========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train=pd.read_excel('cTTD_features_with_Labels/S2/trainset_60.xls')  #reading the xls file into dataframe\n",
    "    validate=pd.read_excel('cTTD_features_with_Labels/S2/validate_20.xls')\n",
    "    test=pd.read_excel('cTTD_features_with_Labels/S2/testset_20.xls')\n",
    "    \n",
    "    x_tr=train.drop(43,axis=1)    #separating the target values\n",
    "    y_tr=train[43]\n",
    "    x_v=validate.drop(43,axis=1)\n",
    "    y_v=validate[43]\n",
    "    x_te=test.drop(43,axis=1)\n",
    "    y_te=test[43]\n",
    "    \n",
    "    x_train=x_tr.to_numpy()        # converting dataframe to numpy array\n",
    "    y_train=y_tr.to_numpy()\n",
    "    x_val=x_v.to_numpy()\n",
    "    y_val=y_v.to_numpy()\n",
    "    x_test=x_te.to_numpy()\n",
    "    y_test=y_te.to_numpy()\n",
    "    \n",
    "    model7(x_train,y_train,x_val,y_val,x_test,y_test)\n",
    "    print(\"==========================================================================================================\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the total analysis done using SGD Classifier.The model is properly tuned with the help of validation set.Several parameters were tuned to increase the model effciency.As it can be seen that accuracy before tuning the parameter was 89 percent  and after tuning it jumps to 94.52 percent.The precision of the model also raise to 94.58 percent after tuning the model.From here,I choose F1 score is a right metric as it seeks a balance between precision and recall.Accuracy will be also right as there is much difference between precision and recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary\n",
    " 1. This is the total analysis done using SGD classifier.\n",
    " 2. First ,datasets was converted into numpy array so that it can be easily put in the model.\n",
    " 3. Then we normally train the model without tuning any of its hyperparameter and then test it on test dataset and observe the       metrics \n",
    " 4. After that we tuned the hyperparameters by varying with different values and checked it on validation set and after gettig       the best hyperparameters and after that we combine both train and validate and train as a whole.\n",
    " 5. After that we checked the accuracy,precision,recall,confusion-matrix as well as F1 score of the testing data with predicted     value\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
